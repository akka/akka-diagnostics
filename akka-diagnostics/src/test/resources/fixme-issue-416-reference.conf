# FIXME see issue #416


akka.diagnostics.checker.disabled-checks = []
akka.diagnostics.recorder.enabled = off

# Snapshot of all cinnamon reference.conf files at 2018-05-14
# Snapshot of all Lagom reference.conf files at 2018-05-14
# Snapshot of all Playframework reference.conf files at 2018-05-14
# would be better to not snapshot but pull in dependencies or something #387

# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#telegraf-reference
cinnamon.chmetrics {
  telegraf-reporter = ${cinnamon.chmetrics.statsd-reporter} {
    telegraf {
      enabled = on
    }
  }
}
#telegraf-reference
cinnamon.test.something = on
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

# Automatically add the Zipkin trace reporter
cinnamon.opentracing.tracer.reporters += zipkin

#opentracing-zipkin-reference
cinnamon.opentracing {
  zipkin {
    factory-class = "cinnamon.opentracing.zipkin.ZipkinReporterFactory" #exclude-from-docs

    # Flush interval for trace span reporter
    flush-interval = 1s

    # Max queue size of trace span reporter
    max-queue-size = 1000

    # Zipkin sender to use for reporting trace spans
    sender = url-connection

    # URL connection sender for reporting directly to a Zipkin API endpoint
    url-connection {
      factory-class = "cinnamon.opentracing.zipkin.sender.URLConnectionSenderFactory" #exclude-from-docs
      # POST URL for Zipkin's v1 api, usually "http://zipkinhost:9411/api/v1/spans"
      endpoint = "http://localhost:9411/api/v1/spans"

      # Encoding to use for trace spans (thrift or json)
      encoding = "thrift"

      # Timeout for establishing URL connection
      connect-timeout = 10s

      # Timeout for connection reads
      read-timeout = 60s

      # Whether GZIP compression is enabled
      compression = true

      # Maximum size of messages
      max-message-size = 5MiB
    }

  }
}
#opentracing-zipkin-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

akka.http.instrumentations += "cinnamon.akka.http.CinnamonAkkaHttpInstrumentation"

# Settings for instrumentation of Akka HTTP.
#
# SERVER SETTINGS
#
# Generic server metrics are automatically created (but can be turned off via configuration). For path specific server metrics
# to be created one has to add configuration.
#
# Settings are grouped per "server" in the configuration. A JVM can handle many Akka HTTP servers and when such a server
# is started, Cinnamon will inquire the configuration to get the server settings.
#
# Each server should define the following settings:
# - "host:port": the IP address and port the setting is valid for, can be set to "*:*" to be valid for all hosts/ports.
# - server-metrics (optional): if set to off, no metrics, server or path, will be created.
#   (By default, server-metrics is set to on, i.e. if there is no explicit setting it will be interpreted as set to on.)
# - paths: a block in which endpoint paths are defined with specific settings per endpoint.
#   - each endpoint path is defined like "x/y/z" { metrics = on }
#   - endpoint paths can have a "*" wildcard at the end, like "x/y/*" to enable metrics for paths starting with "x/y/"
#   - endpoint paths will ignore query parameters, i.e. "x/y?123" will be treated as "x/y".
#
# Here's an example config:
#
# {{{
# cinnamon.akka.http.servers {
#   "192.168.10.1:8080" {
#     paths {
#       "a/b/c" {
#         metrics = on
#       }
#       "x/y/*" {
#         metrics = on
#       }
#     }
#   },
#   "127.0.0.1:*" {
#     paths {
#       "x/*" {
#         metrics = on
#       }
#       "y/*" {
#         metrics = on
#       }
#     }
#   },
#   "192.168.0.1:*" {
#     server-metrics = off
#   }
# }
# }}}
#
#
# CLIENT SETTINGS
#
# By default nothing is instrumented, i.e. without any specific configuration, no client metrics are created.
# Client settings are very similar to server settings above. One difference is that it is possible to name
# the endpoint paths for a specific service via the "service-name" configuration key. If no service name is
# provided the URL address will be used as name, e.g. "192.168.10.10:*" here below.
#
# Here's an example config:
#
# {{{
# cinnamon.akka.http.clients {
#   "192.168.10.1:8080" {
#     service-name = "customerService"
#     paths {
#       "a/b/c" {
#         metrics = on
#       }
#       "x/y/*" {
#         metrics = on
#       }
#     }
#   },
#   "192.168.10.10:*" {
#     paths {
#       "x/*" {
#         metrics = on
#       }
#       "y/*" {
#         metrics = on
#       }
#     }
#   }
# }
# }}}

cinnamon.akka.http {
  servers {}
  clients {}
}

cinnamon.akka.http.meta {
  identity {
    akka-http {
      name = "akka-http"
    }

    client-pool {
      category = "client-pools"
      key = "client-pool"
    }

    client {
      category = "http-clients"
      key = "http-client"
      unknown-host = "hostUnknown"
    }

    server {
      category = "http-servers"
      key = "http-server"
    }

    request-path {
      category = "request-paths"
      key = "request-path"
    }
  }
}

#cinnamon-descriptors-akka-http-client
cinnamon.akka.http.meta {
  descriptor {
    client-pool {
      connections {
        key = "connections"
        name = "Akka HTTP client connections" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Akka HTTP client metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "connection"
        unit-plural-suffix = "connections" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }

    client {
      requests {
        key = "http-client-requests"
        name = "Akka HTTP client requests" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Akka HTTP client metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      service-response-time {
        key = "http-client-service-response-time"
        name = "Akka HTTP client service response time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Akka HTTP client metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-akka-http-client

#cinnamon-descriptors-akka-http-server
cinnamon.akka.http.meta {
  descriptor {
    server {
      connections {
        key = "connections"
        name = "Incoming connections" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Akka HTTP server metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "connection"
        unit-plural-suffix = "connections" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      requests {
        key = "requests"
        name = "Incoming requests" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Akka HTTP server metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "request"
        unit-plural-suffix = "requests" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      responses {
        key = "responses"
        name = "Outgoing responses" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Akka HTTP server metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "response"
        unit-plural-suffix = "responses" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
      #cinnamon-descriptors-akka-http-server
      responses-2xx = ${cinnamon.akka.http.meta.descriptor.server.responses} {
        key = ${cinnamon.akka.http.meta.descriptor.server.responses.key}"-2xx"
        name = ${cinnamon.akka.http.meta.descriptor.server.responses.name}" 2xx"
      }

      responses-3xx = ${cinnamon.akka.http.meta.descriptor.server.responses} {
        key = ${cinnamon.akka.http.meta.descriptor.server.responses.key}"-3xx"
        name = ${cinnamon.akka.http.meta.descriptor.server.responses.name}" 3xx"
      }

      responses-4xx = ${cinnamon.akka.http.meta.descriptor.server.responses} {
        key = ${cinnamon.akka.http.meta.descriptor.server.responses.key}"-4xx"
        name = ${cinnamon.akka.http.meta.descriptor.server.responses.name}" 4xx"
      }

      responses-5xx = ${cinnamon.akka.http.meta.descriptor.server.responses} {
        key = ${cinnamon.akka.http.meta.descriptor.server.responses.key}"-5xx"
        name = ${cinnamon.akka.http.meta.descriptor.server.responses.name}" 5xx"
      }
      #cinnamon-descriptors-akka-http-server

      response-time {
        key = "response-time"
        name = "Outgoing response time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Akka HTTP server metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
      #cinnamon-descriptors-akka-http-server
      response-time-2xx = ${cinnamon.akka.http.meta.descriptor.server.response-time} {
        key = ${cinnamon.akka.http.meta.descriptor.server.response-time.key}"-2xx"
        name = ${cinnamon.akka.http.meta.descriptor.server.response-time.name}" 2xx"
      }

      response-time-3xx = ${cinnamon.akka.http.meta.descriptor.server.response-time} {
        key = ${cinnamon.akka.http.meta.descriptor.server.response-time.key}"-3xx"
        name = ${cinnamon.akka.http.meta.descriptor.server.response-time.name}" 3xx"
      }

      response-time-4xx = ${cinnamon.akka.http.meta.descriptor.server.response-time} {
        key = ${cinnamon.akka.http.meta.descriptor.server.response-time.key}"-4xx"
        name = ${cinnamon.akka.http.meta.descriptor.server.response-time.name}" 4xx"
      }

      response-time-5xx = ${cinnamon.akka.http.meta.descriptor.server.response-time} {
        key = ${cinnamon.akka.http.meta.descriptor.server.response-time.key}"-5xx"
        name = ${cinnamon.akka.http.meta.descriptor.server.response-time.name}" 5xx"
      }
      #cinnamon-descriptors-akka-http-server
    }

    endpoint {
      responses {
        key = "endpoint-responses"
        name = "Outgoing endpoint responses" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Akka HTTP server endpoint metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "response"
        unit-plural-suffix = "responses" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      response-time = {
        key = "endpoint-response-time"
        name = "Outgoing endpoint response time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Akka HTTP server endpoint metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-akka-http-server
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

# Automatically set up the Prometheus backend
cinnamon.backends += prometheus

#prometheus-reference
cinnamon.prometheus {
  backend-class = "cinnamon.prometheus.PrometheusBackend" #exclude-from-docs

  # Prometheus exporters to load
  exporters = ${?cinnamon.chmetrics.exporters} []

  # Whether to include "unique dimensions" as labels.
  # These are labels that are unique to this client,
  # such as host name and application identifier.
  unique-dimensions = on

  # Using the default registry will enable the user to create "native" Prometheus metrics and
  # Cinnamon metrics in the Prometheus default registry. Enabling this feature means that any
  # Prometheus metric,  regardless of how it is created, will be exposed via this exporter.
  use-default-registry = off

  # Settings for Prometheus Summary metrics (used for Cinnamon Recorder)
  # See https://prometheus.io/docs/practices/histograms/ for more information
  summary {
    # Quantiles used for summaries, with tolerated error
    quantiles = [
      { quantile = 0.5,  error = 0.05 },
      { quantile = 0.95, error = 0.01 },
      { quantile = 0.99, error = 0.001 },
    ]

    # Duration of the time window for summaries (how long observations are kept)
    max-age = 10m

    # Number of buckets used to implement the sliding time window for summaries
    age-buckets = 5
  }
}
#prometheus-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

play.ws.instrumentations += "cinnamon.play.CinnamonPlayInstrumentation"

cinnamon.play {
  enabled = on

  # Settings for instrumentation of Play HTTP.
  #
  # SERVER SETTINGS
  #
  # Generic server metrics are automatically created (but can be turned off via configuration). For path specific server metrics
  # to be created one has to add configuration.
  #
  # Each server should define the following settings:
  # - "host:port": the IP address and port the setting is valid for, can be set to "*:*" to be valid for all hosts/ports.
  # - server-metrics (optional): if set to off, no metrics, server or path, will be created.
  #   (By default, server-metrics is set to on, i.e. if there is no explicit setting it will be interpreted as set to on.)
  # - paths: a block in which endpoint paths are defined with specific settings per endpoint.
  #   - each endpoint path is defined like "x/y/z" { metrics = on }
  #   - endpoint paths can have a "*" wildcard at the end, like "x/y/*" to enable metrics for paths starting with "x/y/"
  #   - endpoint paths will ignore query parameters, i.e. "x/y?123" will be treated as "x/y".
  #
  # Here's an example config:
  #
  # {{{
  # cinnamon.play.http.servers {
  #   "192.168.10.1:8080" {
  #     paths {
  #       "a/b/c" {
  #         metrics = on
  #       }
  #       "x/y/*" {
  #         metrics = on
  #       }
  #     }
  #   },
  #   "127.0.0.1:*" {
  #     paths {
  #       "x/*" {
  #         metrics = on
  #       }
  #       "y/*" {
  #         metrics = on
  #       }
  #     }
  #   },
  #   "192.168.0.1:*" {
  #     server-metrics = off
  #   }
  # }
  # }}}
  #
  #
  # CLIENT SETTINGS
  #
  # By default nothing is instrumented, i.e. without any specific configuration, no client metrics are created.
  # Client settings are very similar to server settings above. One difference is that it is possible to name
  # the endpoint paths for a specific service via the "service-name" configuration key. If no service name is
  # provided the URL address will be used as name, e.g. "192.168.10.10:*" here below.
  #
  # Here's an example config:
  #
  # {{{
  # cinnamon.play.http.clients {
  #   "192.168.10.1:8080" {
  #     service-name = "customerService"
  #     paths {
  #       "a/b/c" {
  #         metrics = on
  #       }
  #       "x/y/*" {
  #         metrics = on
  #       }
  #     }
  #   },
  #   "192.168.10.10:*" {
  #     paths {
  #       "x/*" {
  #         metrics = on
  #       }
  #       "y/*" {
  #         metrics = on
  #       }
  #     }
  #   }
  # }
  # }}}
  http {
    servers = {}
    clients = {}
  }

  meta {
    identity {
      play {
        name = "play"
      }

      clients {
        category = "play-clients"
        key = "play-client"
      }

      client {
        category = "http-clients"
        key = "http-client"
      }

      request-path {
        category = "request-paths"
        key = "request-path"
      }
    }
  }
}

#cinnamon-descriptors-play-client
cinnamon.play.meta {
  descriptor {
    client {
      requests {
        key = "play-client-requests"
        name = "Play client requests" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Play client metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "request"
        unit-plural-suffix = "requests" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      service-response-time {
        key = "play-client-service-response-time"
        name = "Play client service response time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Play client metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-play-client
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#jvm-metrics-producer-reference
cinnamon {
  producers += jvm-metrics-producer

  jvm-metrics-producer {
    producer-class = "com.lightbend.cinnamon.jvmmetricsproducer.JvmMetricsProducer" #exclude-from-docs

    memory-usage {
      # Enable memory usage metrics
      metrics = on
      # The category name for all memory usage metrics
      category = "memory-usage"
    }

    garbage-collection {
      # Enable garbage collection metrics
      metrics = on
      # The category name for all garbage collection metrics
      category = "garbage-collection"
    }

    class-loading {
      # Enable class loading metrics
      metrics = on
      # The category name for all class loading metrics
      category = "class-loading"
    }
  }
}
#jvm-metrics-producer-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#elasticsearch-reporter-reference
cinnamon.chmetrics {
  elasticsearch-reporter {
    reporter-class = "com.lightbend.cinnamon.chmetrics.elasticsearch.ElasticsearchReporter" #exclude-from-docs

    # A list of hosts used to connect to elasticsearch.
    # Must be in the format `[http://][username:password@]hostname:port`.
    hosts = ["localhost:9200"]

    # Username and password to be used with all hosts (that don't define credentials directly).
    # Basic authentication is enabled when both username and password are non-empty.
    basic-auth {
      username = ""
      password = ""
    }

    # Milliseconds to wait for an established connection, before the next host in the list is tried.
    timeout = 1000

    # Defines how many metrics are sent per bulk requests.
    bulksize = 2500

    # The name of the index to write to, defaults to metrics.
    index = "cinnamon-metrics"

    # The date format to make sure to rotate to a new index.
    index-date-format = "yyyy-MM"

    # The field name of the timestamp (kibana default is @timestamp).
    timestamp-field-name = "@timestamp"

    # Frequency with which to report metrics.
    frequency = 10s

    # JSON files containing index mappings.
    # Default mapping will be applied if no file is specified.
    index-mapping-file-names = []

    percolation {
      # MetricFilter to define which metrics should be percolated.
      filter = "empty-filter"

      empty-filter {
        filter-class = "com.lightbend.cinnamon.chmetrics.elasticsearch.EmptyFilter"
      }

      # Implementation of the Notifier interface, which is executed upon a matching percolator.
      notifier = "empty-notifier"

      empty-notifier {
        notifier-class = "com.lightbend.cinnamon.chmetrics.elasticsearch.EmptyNotifier"
      }
    }
  }
}
#elasticsearch-reporter-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

cinnamon.opentracing {
  mock {
    factory-class = "cinnamon.opentracing.mock.MockTracerFactory"

    # scope-manager can be thread-local or noop
    scope-manager = thread-local

    # propagator can be printer or text-map
    propagator = text-map
  }
}
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

# Automatically set up the OpenTracing actor instrumentation
akka.instrumentations += "cinnamon.opentracing.OpenTracingActorInstrumentation"

# Automatically set up the OpenTracing Akka HTTP instrumentation
akka.http.instrumentations += "cinnamon.opentracing.OpenTracingAkkaHttpInstrumentation"

# Automatically set up the OpenTracing Play WS instrumentation
play.ws.instrumentations += "cinnamon.opentracing.OpenTracingPlayWSInstrumentation"

cinnamon.opentracing {
  # Tracer factories (list of config paths)
  tracers = ${?cinnamon.opentracing.tracers} []

  akka {
    # Whether to include system messages in actor traces
    trace-system-messages = off

    # Whether to deregister the global tracer on actor system shutdown
    # Only applies if Cinnamon created and registered the tracer on system start
    deregister-global-tracer-on-shutdown = on
  }
}
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#opentracing-zipkin-kafka-reference
cinnamon.opentracing {
  zipkin {
    kafka {
      factory-class = "cinnamon.opentracing.zipkin.kafka.KafkaSenderFactory" #exclude-from-docs
      # Initial set of kafka servers to connect to (must be specified)
      bootstrap-servers = []

      # Kafka topic to send trace spans to
      topic = "zipkin"

      # Encoding to use for trace spans (thrift or json)
      encoding = "thrift"

      # Property overrides for producer configs (http://kafka.apache.org/0102/documentation.html#producerconfigs)
      properties {}

      # Maximum size of messages
      max-message-size = 1MB
    }
  }
}
#opentracing-zipkin-kafka-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

cinnamon.lagom {
  # Whether to instrument Lagom circuit breakers
  circuit-breakers = on

  # Settings for instrumentation of Lagom HTTP.
  #
  # SERVER SETTINGS
  #
  # Generic server metrics are automatically created (but can be turned off via configuration). For path specific server metrics
  # to be created one has to add configuration.
  #
  # Each server should define the following settings:
  # - "host:port": the IP address and port the setting is valid for, can be set to "*:*" to be valid for all hosts/ports.
  # - server-metrics (optional): if set to off, no metrics, server or path, will be created.
  #   (By default, server-metrics is set to on, i.e. if there is no explicit setting it will be interpreted as set to on.)
  # - paths: a block in which endpoint paths are defined with specific settings per endpoint.
  #   - each endpoint path is defined like "x/y/z" { metrics = on }
  #   - endpoint paths can have a "*" wildcard at the end, like "x/y/*" to enable metrics for paths starting with "x/y/"
  #   - endpoint paths will ignore query parameters, i.e. "x/y?123" will be treated as "x/y".
  #
  # Here's an example config:
  #
  # {{{
  # cinnamon.lagom.http.servers {
  #   "192.168.10.1:8080" {
  #     paths {
  #       "a/b/c" {
  #         metrics = on
  #       }
  #       "x/y/*" {
  #         metrics = on
  #       }
  #     }
  #   },
  #   "127.0.0.1:*" {
  #     paths {
  #       "x/*" {
  #         metrics = on
  #       }
  #       "y/*" {
  #         metrics = on
  #       }
  #     }
  #   },
  #   "192.168.0.1:*" {
  #     server-metrics = off
  #   }
  # }
  # }}}
  #
  #
  # CLIENT SETTINGS
  #
  # By default nothing is instrumented, i.e. without any specific configuration, no client metrics are created.
  # Client settings are very similar to server settings above. One difference is that it is possible to name
  # the endpoint paths for a specific service via the "service-name" configuration key. If no service name is
  # provided the URL address will be used as name, e.g. "192.168.10.10:*" here below.
  #
  # Here's an example config:
  #
  # {{{
  # cinnamon.lagom.http.clients {
  #   "192.168.10.1:8080" {
  #     service-name = "customerService"
  #     paths {
  #       "a/b/c" {
  #         metrics = on
  #       }
  #       "x/y/*" {
  #         metrics = on
  #       }
  #     }
  #   },
  #   "192.168.10.10:*" {
  #     paths {
  #       "x/*" {
  #         metrics = on
  #       }
  #       "y/*" {
  #         metrics = on
  #       }
  #     }
  #   }
  # }
  # }}}
  http {
    servers {}
    clients {}
  }
}

cinnamon.lagom.meta {
  identity {
    lagom {
      name = "lagom"
    }

    circuit-breaker {
      category = "circuit-breakers"
      key = "circuit-breaker"
    }
  }
}

#cinnamon-descriptors-lagom-circuit-breaker-metrics
#cinnamon-descriptors-lagom-circuit-breaker-events
cinnamon.lagom.meta {
  descriptor {
    circuit-breaker {
      #cinnamon-descriptors-lagom-circuit-breaker-events
      state {
        key = "state"
        name = "State" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Circuit breaker metrics"] #exclude-from-docs
        unit-type = "none"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      throughput {
        key = "throughput"
        name = "Throuphput" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Circuit breaker metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "request"
        unit-plural-suffix = "requests" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      success {
        key = "success"
        name = "Success" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Circuit breaker metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "request"
        unit-plural-suffix = "requests" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      failure {
        key = "failure"
        name = "Failure" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Circuit breaker metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "request"
        unit-plural-suffix = "requests" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      latency {
        key = "latency"
        name = "Latency" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Circuit breaker metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
      #cinnamon-descriptors-lagom-circuit-breaker-metrics

      #cinnamon-descriptors-lagom-circuit-breaker-events
      state-change {
        key = "circuit-breaker-state-change"
        name = "CircuitBreakerStateChange" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
      #cinnamon-descriptors-lagom-circuit-breaker-metrics
    }
  }
}
#cinnamon-descriptors-lagom-circuit-breaker-metrics
#cinnamon-descriptors-lagom-circuit-breaker-events
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#datadog-reference
cinnamon.chmetrics {
  datadog-reporter = ${cinnamon.chmetrics.statsd-reporter} {
    dogstatsd {
      enabled = on

      # Prefix must be "lightbend" to enable the Lightbend Platform integration in Datadog
      prefix = "lightbend"
    }

    report {
      # Histogram fields to report for metrics
      histogram = ["max", "p99"]

      # Meter fields to report for metrics
      meter = ["min1_rate"]
    }
  }
}
#datadog-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#opentracing-zipkin-scribe-reference
cinnamon.opentracing {
  zipkin {
    scribe {
      factory-class = "cinnamon.opentracing.zipkin.scribe.ScribeSenderFactory" #exclude-from-docs
      # Host of Scribe trace collector
      host = "localhost"

      # Port of Scribe trace collector
      port = 9410

      # Timeout for socket reads
      socket-timeout = 60s

      # Timeout for connections
      connect-timeout = 10s

      # Maximum size of messages (scribe default is 16384000 bytes)
      max-message-size = 16000KiB
    }
  }
}
#opentracing-zipkin-scribe-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

# Automatically set up the Cinnamon actor instrumentation
akka.instrumentations += "cinnamon.akka.CinnamonActorInstrumentation"

cinnamon {
  # Shows status of config loading - especially useful if there are errors in the Cinnamon configuration
  show-config-info = true

  # Shows loaded config settings
  show-loaded-config-settings = false

  # Settings for instrumentation of Actor classes.
  #
  # By default nothing is instrumented, i.e. without any explicit settings nothing will be traced.
  #
  # The idea is that you define "groups" of what you want to instrument. All groups are identified by their names.
  # The name of the group is the key of the setting, e.g. "myGroup" { ... }
  # It is possible to use the actor path/class/package as the name of the group. The benefit of doing this is that
  # there is no need to explicitly define an "includes" as the name will be interpreted as what to include.
  #
  # The only mandatory value, apart from what to instrument, is how the data should be reported (report-by).
  # There are three ways data can be reported; group, class and/or instance.
  #
  # Group reporting means that all actors defined in the includes setting will report to one common group. This means
  # that if the group includes ActorA and ActorB and you create 3 instances of ActorA and 2 of ActorB the "running actors"
  # of the group will be 5. Group reporting is great for grouping multiple actors together to get statistics from a
  # holistic perspective.
  #
  # Class reporting means that all actor instances belonging to that class will report to it. For example, let's say
  # you have class reporting of ActorA and you create two instances of it you now have 2 "running actors". Class reporting
  # is great to get an average view of how an actor class is performing.
  #
  # Instance reporting is the most fine grained reporting and works on a per instance level. This means that if you
  # are instrumenting ActorA and create two instances (with names "actorA1" and "actorA2") there will be two
  # reports created "actorA1" and "actorA2" and each of them have 1 "running actors".
  #
  # It is possible to "report-by" a combination of the three above, e.g. report-by = [group, instance].
  #
  # The following settings are supported:
  #   - report-by - what way to report this group in - supports a combination of: group, class, instance.
  #   - name - the name of the setting.
  #   - includes - a value or array of what actor path/class/package to include in the group - supports wildcard ('*').
  #   - excludes - a value or array of what actor path/class/package to exclude from the group - supports wildcard ('*').
  #   - routers - a flag whether or not to instrument routers, defaults to on.
  #   - experimental.connections - a flag that toggles per connection metrics, if it is enabled on both sender and receiver
  #     NOTE: experimental.connections can generate lots of metrics if there are many instances, classes, groups communicating
  #   - thresholds - contains threshold values used to monitor that no values exceed some limits - if so an event is created.
  #     - mailbox-size - an integer
  #     - stash-size - an integer
  #     - mailbox-time - a duration
  #     - processing-time - a duration
  #     - remote-message-size - a size in bytes
  #
  #
  # Here's an example config:
  #
  # {{{
  # cinnamon.akka.actors {
  #   "some.package.*" = {
  #     report-by = instance
  #     routers = off
  #     thresholds {
  #       mailbox-size = 1000
  #       stash-size = 100
  #       mailbox-time = 2000ms
  #       processing-time = 500ms
  #       remote-message-size = 1M
  #     }
  #   }
  #
  #   "myGroup" {
  #     report-by = [group, class]
  #     includes = ["com.a.*", "com.b.*"]
  #     excludes = ["com.a.x.*"]
  #   }
  # }
  # }}}
  #
  # The above config would render the following setting:
  #
  # name: "some.package.*"
  # report-by: instance
  # routers: off
  # includes: ["some.package.*"]
  # excludes: []
  # mailbox-size: 1000
  # stash-size: 100
  # mailbox-time: 2000ms
  # processing-time: 500ms
  # remote-message-size: 1M
  #
  # and
  #
  # name: "myGroup"
  # report-by: [group, class]
  # routers: on
  # includes: ["com.a.*", "com.b.*"]
  # excludes: ["com.a.x.*"]
  # mailbox-size: N/A
  # stash-size: N/A
  # mailbox-time: N/A
  # processing-time: N/A
  # remote-message-size: N/A
  akka.actors {}

  # Default actor configuration settings.
  # Used as fallback config for each actor configuration section.
  defaults.akka.actors {}

  akka.remote {
    # Enable or disable the timing of remote serialization
    serialization-timing = off

    # Enable or disable events for large messages
    #
    # For example to send events if messages are larger than 1k bytes:
    # large-message-events-size = 1k
    large-message-events-size = off

    # Enable or disable failure detector related metrics (e.g. phi accrual or node quarantined information)
    failure-detector-metrics = off
  }

  akka.cluster {
    # Enable or disable domain related cluster events
    domain-events = off

    # Enable or disable member related cluster events
    member-events = off

    # Enable or disable events related to split brain resolver
    split-brain-resolver-events = off

    # Enable or disable cluster singleton events
    singleton-events = off

    # Enable or disable shard region associated events and metrics
    shard-region-info = off
  }

  # Enabled metric dimensions (will be visible in metric keys and tags)
  akka.dimensions = ["actor-system", "dispatcher"]

  # Settings for instrumenting dispatchers.
  #
  # Dispatcher names can have a trailing wildcard. By default basic information is gathered for
  # all dispatchers.
  akka.dispatchers {
    # Names of dispatchers for which to collect the built in Executor information.
    basic-information {
      names = ["*"]
    }

    # Names of dispatchers for which to collect queue time, processing time, and queue sizes.
    time-information {
      names = []
    }
  }

  akka.persistence {
    # Enable or disable persistence related metrics
    metrics = off

    # Enable or disable persistence related events
    events = off
  }

  stopwatch {
    # Thresholds for stopwatches
    thresholds {}
  }

  deprecation {
    # Shows/warns about deprecated configuration settings
    show-deprecated-settings = true

    documentation-url = "https://developer.lightbend.com/docs/telemetry/current/"

    deprecated-settings = [
      {
        path = "cinnamon.chmetrics.actors"
        text = "The actor configuration should be under 'cinnamon.akka.actors', not 'cinnamon.chmetrics.actors'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.0.html#actor-configuration"
        from-version = "2.0"
      },
      {
        path = "cinnamon.chmetrics.trace"
        text = "The trace configuration should be under 'cinnamon.trace', not 'cinnamon.chmetrics.trace'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.0.html#trace-configuration"
        from-version = "2.0"
      },
      {
        path = "cinnamon.takipi.actors"
        text = "The actor configuration should be under 'cinnamon.akka.actors', not 'cinnamon.takipi.actors'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.0.html#actor-configuration"
        from-version = "2.0"
      },
      {
        path = "cinnamon.takipi.trace"
        text = "The trace configuration should be under 'cinnamon.trace', not 'cinnamon.takipi.trace'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.0.html#trace-configuration"
        from-version = "2.0"
      },
      {
        path = "cinnamon.chmetrics.histogram.size"
        text = "The sliding-window reservoir size is now configured via 'cinnamon.chmetrics.histogram.sliding-window.size'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.3.html#histogram-reservoirs"
        from-version = "2.3"
      },
      {
        path = "cinnamon.chmetrics.histogram.time"
        text = "The sliding-time-window reservoir time is now configured via 'cinnamon.chmetrics.histogram.sliding-time-window.time'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.3.html#histogram-reservoirs"
        from-version = "2.3"
      },
      {
        path = "cinnamon.chmetrics.statsd-reporter.server-id"
        text = "The server identifier is now configured via 'cinnamon.host'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.5.html#host-and-application-identifiers"
        from-version = "2.5"
      },
      {
        path = "cinnamon.chmetrics.statsd-reporter.application-id"
        text = "The application identifier is now configured via 'cinnamon.application'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.5.html#host-and-application-identifiers"
        from-version = "2.5"
      },
      {
        path = "cinnamon.chmetrics.conductr-statsd-reporter.server-id"
        text = "The server identifier is now configured via 'cinnamon.host'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.5.html#host-and-application-identifiers"
        from-version = "2.5"
      },
      {
        path = "cinnamon.chmetrics.conductr-statsd-reporter.application-id"
        text = "The application identifier is now configured via 'cinnamon.application'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.5.html#host-and-application-identifiers"
        from-version = "2.5"
      },
      {
        path = "cinnamon.trace.thresholds"
        text = "Trace Span is now named Stopwatch. Thresholds are configured via 'cinnamon.stopwatch.thresholds'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.5.html#spans"
        from-version = "2.5"
      },
      {
        path = "cinnamon.opsclarity"
        text = "The OpsClarity reporter is now configured via 'cinnamon.chmetrics.opsclarity-reporter'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.6.html#opsclarity-and-datadog-reporters"
        from-version = "2.6"
      }
      {
        path = "cinnamon.datadog"
        text = "The Datadog reporter is now configured via 'cinnamon.chmetrics.datadog-reporter'. See: "${cinnamon.deprecation.documentation-url}"/project/migration-2.6.html#opsclarity-and-datadog-reporters"
        from-version = "2.6"
      }
    ]
  }
}

cinnamon.akka.meta {
  identity {
    akka {
      name = "akka"
    }

    system {
      category = "systems"
      key = "actor-system"
    }

    address {
      category = "addresses"
      key = "address"
    }

    dispatcher {
      category = "dispatchers"
      key = "dispatcher"
    }

    actor {
      category = "actors"
      key = "actor"
    }

    self-node {
      category = "self-nodes"
      key = "self-node"
    }

    remote-node {
      category = "remote-nodes"
      key = "remote-node"
    }

    stopwatch {
      category = "stopwatches"
      key = "stopwatch"
    }

    router {
      category = "routers"
      key = "router"
    }

    experimental.connection {
      category = "connections"
      key = "connection"
    }
  }

  descriptor {
    custom-metrics {
      group-name = "metrics"
    }
  }
}

#cinnamon-descriptors-dispatcher
cinnamon.akka.meta {
  descriptor {
    dispatcher {
      queue-size {
        key = "queue-size"
        name = "Queue size" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "task"
        unit-plural-suffix = "tasks" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      queue-time {
        key = "queue-time"
        name = "Queue time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      processing {
        key = "processing"
        name = "Processing" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "task"
        unit-plural-suffix = "tasks" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      processing-time {
        key = "processing-time"
        name = "Processing time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-dispatcher
#cinnamon-descriptors-actor
cinnamon.akka.meta {
  descriptor {
    actor {
      running-actors {
        key = "running-actors"
        name = "Actors (running)" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Actor processing metrics", "Actor metrics/Actor mailbox metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "actor"
        unit-plural-suffix = "actors" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      mailbox-size {
        key = "mailbox-size"
        name = "Mailbox size" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Actor mailbox metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "msg"
        unit-plural-suffix = "msgs" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      stash-size {
        key = "stash-size"
        name = "Stash size" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Actor stash metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "msg"
        unit-plural-suffix = "msgs" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      mailbox-time {
        key = "mailbox-time"
        name = "Mailbox time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Actor mailbox metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      processed-messages {
        key = "processed-messages"
        name = "Processed messages" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Actor processing metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "msg"
        unit-plural-suffix = "msgs" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      sent-messages {
        key = "sent-messages"
        name = "Sent messages" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Actor sent metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "msg"
        unit-plural-suffix = "msgs" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      processing-time {
        key = "processing-time"
        name = "Processing time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Actor processing metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      dropped-messages {
        key = "dropped-messages"
        name = "Dropped messages" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Actor mailbox metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "msg"
        unit-plural-suffix = "msgs" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-actor
#cinnamon-descriptors-actor-events
cinnamon.akka.meta {
  descriptor {
    actor {
      mailbox-size-limit {
        key = "mailbox-size-limit"
        name = "MailboxSizeLimit" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      stash-size-limit {
        key = "stash-size-limit"
        name = "StashSizeLimit" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      mailbox-time-limit {
        key = "mailbox-time-limit"
        name = "MailboxTimeLimit" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      processing-time-limit {
        key = "processing-time-limit"
        name = "ProcessingTimeLimit" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      log-error {
        key = "log-error"
        name = "LogError" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      log-warning {
        key = "log-warning"
        name = "LogWarning" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      unhandled-message {
        key = "unhandled-message"
        name = "UnhandledMessage" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      dead-letter {
        key = "dead-letter"
        name = "DeadLetter" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      actor-failure {
        key = "actor-failure"
        name = "ActorFailure" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-actor-events
#cinnamon-descriptors-actor-remoting
cinnamon.akka.meta {
  descriptor {
    actor {
      remote-sent-messages {
        key = "remote-sent-messages"
        name = "Remote sent messages" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Remote actor metrics/Remote actor sent metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "msg"
        unit-plural-suffix = "msgs" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      remote-sent-message-size {
        key = "remote-sent-message-size"
        name = "Remote sent message size" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Remote actor metrics/Remote actor sent metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "byte"
        unit-plural-suffix = "bytes" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      remote-serialization-time {
        key = "remote-serialization-time"
        name = "Remote serialization time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Remote actor metrics/Remote actor sent metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      remote-received-messages {
        key = "remote-received-messages"
        name = "Remote received messages" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Remote actor metrics/Remote actor received metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "msg"
        unit-plural-suffix = "msgs" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      remote-received-message-size {
        key = "remote-received-message-size"
        name = "Remote received message size" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Remote actor metrics/Remote actor received metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "byte"
        unit-plural-suffix = "bytes" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      remote-deserialization-time {
        key = "remote-deserialization-time"
        name = "Remote deserialization time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Remote actor metrics/Remote actor received metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-actor-remoting
#cinnamon-descriptors-actor-remoting-events
cinnamon.akka.meta {
  descriptor {
    actor {
      remote-large-message-received {
        key = "remote-large-message-received"
        name = "Remote large message received" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      remote-large-message-sent {
        key = "remote-large-message-sent"
        name = "Remote large message sent" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-actor-remoting-events
#cinnamon-descriptors-actor-persistence
cinnamon.akka.meta {
  descriptor {
    actor {
      persistence-recovery-time {
        key = "persistence-recovery-time"
        name = "Persistence recovery time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      persistence-recovery-failure-time {
        key = "persistence-recovery-failure-time"
        name = "Persistence recovery failure time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-actor-persistence
#cinnamon-descriptors-actor-persistence-events
cinnamon.akka.meta {
  descriptor {
    actor {
      persistence-recovery-failed {
        key = "persistence-recovery-failed"
        name = "Persistence recovery failed" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      persistence-persist-failed {
        key = "persistence-persist-failed"
        name = "Persistence persist failed" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      persistence-persist-rejected {
        key = "persistence-persist-rejected"
        name = "Persistence persist rejected" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-actor-persistence-events
#cinnamon-descriptors-shard
cinnamon.akka.meta {
  descriptor {
    shard {
      shard-region-messages-delivered {
        key = "shard-region-messages-delivered"
        name = "Shard region messages delivered" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "msg"
        unit-plural-suffix = "msgs" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-shard
#cinnamon-descriptors-shard-events
cinnamon.akka.meta {
  descriptor {
    shard {
      shard-region-event {
        key = "shard-region-event"
        name = "Shard region event" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      shard-region-proxy-event {
        key = "shard-region-proxy-event"
        name = "Shard region proxy event" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-shard-events
#cinnamon-descriptors-router
cinnamon.akka.meta {
  descriptor {
    router {
      router-routed-messages {
        key = "router-routed-messages"
        name = "Router routed messages" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Router metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "msg"
        unit-plural-suffix = "msgs" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      router-processing-time {
        key = "router-processing-time"
        name = "Router processing time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Actor metrics/Router metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-router
#cinnamon-descriptors-persistence
cinnamon.akka.meta {
  descriptor {
    persistence {
      recovery-permitter-max-permits-value {
        key = "recovery-permitter-max-permits-value"
        name = "RecoveryPermitter max permits value" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Persistence metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "permit"
        unit-plural-suffix = "permits" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      recovery-permitter-used-permits-value {
        key = "recovery-permitter-used-permits-value"
        name = "RecoveryPermitter used permits value" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Persistence metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "permit"
        unit-plural-suffix = "permits" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      recovery-permitter-pending-actors-value {
        key = "recovery-permitter-pending-actors-value"
        name = "RecoveryPermitter pending actors value" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Persistence metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "actor"
        unit-plural-suffix = "actors" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-persistence
#cinnamon-descriptors-remoting
cinnamon.akka.meta {
  descriptor {
    node {
      node-quarantines {
        key = "node-quarantines"
        name = "Node quarantines" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Remote node events"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "event"
        unit-plural-suffix = "events" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      phi-accrual-value {
        key = "phi-accrual-value"
        name = "Phi accrual value" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Remote node events"] #exclude-from-docs
        unit-type = "none"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      phi-accrual-threshold-value {
        key = "phi-accrual-threshold-value"
        name = "Phi accrual thresdhold value" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Remote node events"] #exclude-from-docs
        unit-type = "none"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-remoting
#cinnamon-descriptors-remoting-events
cinnamon.akka.meta {
  descriptor {
    node {
      node-quarantined-event {
        key = "node-quarantined-event"
        name = "Node quarantined event" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-remoting-events
#cinnamon-descriptors-cluster-events
cinnamon.akka.meta {
  descriptor {
    node {
      cluster-domain-event {
        key = "cluster-domain-event"
        name = "Cluster domain event" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      cluster-member-event {
        key = "cluster-member-event"
        name = "Cluster member event" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      split-brain-resolver-event {
        key = "split-brain-resolver-event"
        name = "Split brain resolver event" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      cluster-singleton-event {
        key = "cluster-singleton-event"
        name = "Cluster singleton event" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-cluster-events
#cinnamon-descriptors-stopwatch
cinnamon.akka.meta {
  descriptor {
    stopwatch {
      stopwatch-time {
        key = "stopwatch-time"
        name = "Stopwatch time" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Stopwatch metrics"] #exclude-from-docs
        unit-type = "nanoseconds"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      stopwatch-rate {
        key = "stopwatch-rate"
        name = "Stopwatch rate" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["Stopwatch metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "event"
        unit-plural-suffix = "events" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-stopwatch
#cinnamon-descriptors-stopwatch-events
cinnamon.akka.meta {
  descriptor {
    stopwatch {
      stopwatch-time-limit {
        key = "stopwatch-time-limit"
        name = "StopwatchTimeLimit" #exclude-from-docs
        group-name = "events" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-stopwatch-events

# per connection metrics not in the docs
cinnamon.akka.meta {
  descriptor {
    actor {
      errors {
        key = "errors"
        name = "Errors" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      warnings {
        key = "warnings"
        name = "Warnings" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = [] #exclude-from-docs
        unit-type = "none" #exclude-from-docs
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#opsclarity-reference
cinnamon.chmetrics {
  opsclarity-reporter = ${cinnamon.chmetrics.statsd-reporter} {
    # Port of DogStatsD collector for OpsClarity agent (default is 10101)
    port = 10101

    dogstatsd {
      enabled = on
    }

    report {
      # Histogram fields to report for metrics
      histogram = ["max", "mean", "min", "p95", "p99"]

      # Meter fields to report for metrics
      meter = ["min1_rate", "samples"]
    }
  }
}
#opsclarity-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

cinnamon.sandbox {
  elasticsearch {
    host = "localhost"
    port = 9200
    username = "elastic"
    password = "changeme"
    location = ${cinnamon.sandbox.elasticsearch.host}":"${cinnamon.sandbox.elasticsearch.port}
    uri = "http://"${cinnamon.sandbox.elasticsearch.username}":"${cinnamon.sandbox.elasticsearch.password}"@"${cinnamon.sandbox.elasticsearch.location}
    index = "cinnamon-events"
    frequency = 10s
  }

  akka.actors {
    default-by-class {
      includes = "/user/*"
      report-by = class
    }
  }

  akka.remote {
    serialization-timing = on
    failure-detector-metrics = on
  }

  akka.cluster {
    domain-events = on
    member-events = on
    singleton-events = on
    shard-region-info = on
  }

  akka.dispatchers {
    basic-information {
      names = ["*"]
    }
    time-information {
      names = ["*"]
    }
  }

  akka.http {
    servers {
      "*:*" {
        paths {
          "*" {
            metrics = on
          }
        }
      }
    }
    clients {
      "*:*" {
        paths {
          "*" {
            metrics = on
          }
        }
      }
    }
  }
}
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

# Automatically set up the SLF4J MDC actor instrumentation
akka.instrumentations += "cinnamon.slf4j.mdc.MdcActorInstrumentation"

# Automatically set up the SLF4J MDC Akka HTTP instrumentation
akka.http.instrumentations += "cinnamon.slf4j.mdc.MdcAkkaHttpInstrumentation"

# Automatically set up the SLF4J MDC Play WS instrumentation
play.ws.instrumentations += "cinnamon.slf4j.mdc.MdcPlayWSInstrumentation"

cinnamon {
  slf4j.mdc {
    # List of MDC keys to transfer across async boundaries.
    # When configured, only the specified keys will be transferred,
    # otherwise all keys in the MDC will be included by default.
    filter = []

    serialization {
      # Maximum bytes for serialized MDC sent with remote messages or encoded headers.
      limit = 512 bytes
    }

    http {
      # MDC propagation approach to use for HTTP messages (encoded-header or mapped-headers)
      propagation = encoded-header

      encoded-header {
        propagation-class = "cinnamon.slf4j.mdc.MdcAkkaHttpInstrumentation$EncodedHeader"

        # Name of header for encoded MDC
        name = "Cinnamon-MDC"
      }

      mapped-headers {
        propagation-class = "cinnamon.slf4j.mdc.MdcAkkaHttpInstrumentation$MappedHeaders"

        # Prefix for each MDC key as a header name
        prefix = "CNMDC-"
      }
    }
  }
}
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#http-reporter-reference
cinnamon.chmetrics {
  http-reporter {
    reporter-class = "com.lightbend.cinnamon.chmetrics.http.HttpReporter" #exclude-from-docs

    # Time unit to convert rates to
    convert-rates-to = "SECONDS"

    # Time unit to convert durations to
    convert-durations-to = "MILLISECONDS"

    # Frequency with which to report metrics
    frequency = 5s

    # Interface accept connections on
    host = "127.0.0.1"

    # Port to accept connections on
    port = 8080

    # Configuration of the actor system used by the http reporter
    reporter-actor-system {
      akka.instrumentations = []
      akka.http.instrumentations = []
    }
  }
}
#http-reporter-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

# Automatically add the Jaeger client tracer, used for both Jaeger and Zipkin backends
cinnamon.opentracing.tracers += tracer

#opentracing-tracer-reference
cinnamon.opentracing {
  tracer {
    factory-class = "cinnamon.opentracing.jaeger.client.JaegerTracerFactory" #exclude-from-docs
    reporters = ${?cinnamon.opentracing.tracer.reporters} [] #exclude-from-docs

    # Service name for this application, defaults to the `cinnamon.application` identifier when not set
    service-name = null

    # Tags added to all trace spans (key:value pairs)
    tags {}

    # Trace sampler to use
    sampler = rate-limiting-sampler

    rate-limiting-sampler {
      factory-class = "cinnamon.opentracing.jaeger.client.sampler.RateLimitingSamplerFactory" #exclude-from-docs
      # Maximum number of sampled traces per second
      max-traces-per-second = 10
    }

    probabilistic-sampler {
      factory-class = "cinnamon.opentracing.jaeger.client.sampler.ProbabilisticSamplerFactory" #exclude-from-docs
      # Probabilistic sampling rate, between 0.0 and 1.0
      sampling-rate = 0.001
    }

    const-sampler {
      factory-class = "cinnamon.opentracing.jaeger.client.sampler.ConstSamplerFactory" #exclude-from-docs
      # Constant decision on whether to sample traces
      # Note: this sampler is NOT recommended for production
      decision = true
    }

    # Propagation codecs for cross-process tracing (multiple codecs can be active)
    # Include B3 propgation with: `cinnamon.opentracing.tracer.propagations += b3-propagation`
    propagations = [jaeger-propagation]

    jaeger-propagation {
      factory-class = "cinnamon.opentracing.jaeger.client.propagation.JaegerPropagationFactory" #exclude-from-docs
      # Whether to URL encode the trace context for HTTP header propagation
      http-header-url-encoding = on
    }

    b3-propagation {
      factory-class = "cinnamon.opentracing.jaeger.client.propagation.B3PropagationFactory" #exclude-from-docs
    }

    # Log trace spans with SLF4J (can be used for debugging the tracer)
    # Set `cinnamon.opentracing.tracer.reporters += trace-logging`
    trace-logging {
      factory-class = "cinnamon.opentracing.jaeger.client.reporter.LoggingReporterFactory" #exclude-from-docs
      # Name of SLF4J logger to use when logging
      logger = "cinnamon.opentracing.Tracer"
    }

  }
}
#opentracing-tracer-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

cinnamon.backends += logging

cinnamon.logging {
  backend-class = "cinnamon.slf4j.event.Slf4jEventBackend"

  slf4j-events {
    # Will add quotes around the key/value pairs that are being logged, e.g. "actor-class"="sample.bottleneck.BusinessLogicActor".
    # This can be used to provide easier parsing of the logged output. Especially if there are spaces in the logged output.
    # Feature is off by default.
    use-quotes = off
  }
}
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

# Automatically set up the Coda Hale Metrics backend
cinnamon.backends += chmetrics

cinnamon {
  chmetrics {
    backend-class = "cinnamon.chmetrics.CodaHaleBackend"

    # Key for the registry when it's being added to "com.codahale.metrics.SharedMetricRegistries".
    registry-name = "cinnamon-registry"

    histogram {
      # Change the histogram reservoir type used
      # Allowed types are:
      # default
      #   currently defaults to exponentially-decaying
      # exponentially-decaying
      # uniform
      # sliding-window
      #   has extra config option 'size = <n>' for the number of elements
      #   in the window with a default value of 8192
      # sliding-time-window
      #   has extra config option 'time = <t>' for time of the window
      #   with a default value of 5 seconds
      #
      # More information on the different types can be found here
      # https://dropwizard.github.io/metrics/3.1.0/manual/core/#histograms
      reservoir = "default"

      default {
        factory-class = ${cinnamon.chmetrics.histogram.exponentially-decaying.factory-class}
      }

      exponentially-decaying {
        factory-class = "com.lightbend.cinnamon.chmetrics.histogram.ExponentiallyDecayingReservoirFactory"
      }

      uniform {
        factory-class = "com.lightbend.cinnamon.chmetrics.histogram.UniformReservoirFactory"
      }

      sliding-window {
        factory-class = "com.lightbend.cinnamon.chmetrics.histogram.SlidingWindowReservoirFactory"

        # size for sliding-window histogram
        size = 8192
      }

      sliding-time-window {
        factory-class = "com.lightbend.cinnamon.chmetrics.histogram.SlidingTimeWindowReservoirFactory"

        # time for sliding-time-window histogram
        time = 5 seconds
      }
    }

    # Settings specific to metric hints
    hints {}

    # The named reporters to load
    reporters = ${?cinnamon.chmetrics.reporters} []

    # The named registrants to load
    registrants = ${?cinnamon.chmetrics.registrants} []

    # Metric key Namer to use
    namer = "default-namer"

    # Metric key Formatter to use
    formatter = "default-formatter"
  }
}

#namer-reference
cinnamon.chmetrics {
  default-namer {
    # Fully qualified class name for the namer
    namer-class = "com.lightbend.cinnamon.chmetrics.reporter.namer.DefaultNamer"
  }
}
#namer-reference

#formatter-reference
cinnamon.chmetrics {
  default-formatter {
    # Fully qualified class name for the formatter
    formatter-class = "com.lightbend.cinnamon.chmetrics.reporter.formatter.DefaultFormatter"

    # Delimiter string for the default formatter
    delimiter = "."

    # Encoding replacements for the default formatter
    encode = [
      {
        from = "."
        to = "_"
      },
      {
        from = "@"
        to = "_"
      },
      {
        from = ":"
        to = "_"
      },
      {
        from = "/"
        to = "_"
      }
    ]
  }
}
#formatter-reference

#jmx-reporter-reference
cinnamon.chmetrics {
  jmx-reporter {
    reporter-class = "com.lightbend.cinnamon.chmetrics.reporter.provided.JmxReporter" #exclude-from-docs

    # Time unit to convert rates to
    convert-rates-to = "SECONDS"

    # Time unit to convert durations to
    convert-durations-to = "MILLISECONDS"
  }
}
#jmx-reporter-reference

#console-reporter-reference
cinnamon.chmetrics {
  console-reporter {
    reporter-class = "com.lightbend.cinnamon.chmetrics.reporter.provided.ConsoleReporter" #exclude-from-docs

    # Time unit to convert rates to
    convert-rates-to = "SECONDS"

    # Time unit to convert durations to
    convert-durations-to = "MILLISECONDS"

    # Format numbers for this locale
    formatted-for = "en"

    # Frequency with which to report metrics
    frequency = 5s
  }
}
#console-reporter-reference

#slf4j-reporter-reference
cinnamon.chmetrics {
  slf4j-reporter {
    reporter-class = "com.lightbend.cinnamon.chmetrics.reporter.provided.Slf4jReporter" #exclude-from-docs

    # Time unit to convert rates to
    convert-rates-to = "SECONDS"

    # Time unit to convert durations to
    convert-durations-to = "MILLISECONDS"

    # Logger name to output to
    output-to = "output-sink"

    # Frequency with which to report metrics
    frequency = 5s
  }
}
#slf4j-reporter-reference

cinnamon.chmetrics {
  nop-reporter {
    reporter-class = "com.lightbend.cinnamon.chmetrics.reporter.provided.NOPReporter"
  }
}

#default-filter
cinnamon.chmetrics {
  default-filter {
    filter-class = "com.lightbend.cinnamon.chmetrics.reporter.filter.DefaultFilter"
  }
}
#default-filter
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

cinnamon.backends += contrail

cinnamon {
  contrail {
    backend-class = "cinnamon.contrail.ContrailBackend"
  }
}

contrail.syslog.server.elasticsearch.index-mapping-file-names += "cinnamon_events.json"
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#prometheus-httpserver-reference
cinnamon.prometheus {
  http-server {
    exporter-class = "com.lightbend.cinnamon.prometheus.httpserver.PrometheusHttpServer" #exclude-from-docs

    # Host to bind the Prometheus HTTP server
    host = ""

    # Port to bind the Prometheus HTTP server
    port = 9001

    # Whether to use daemon threads for the HTTP server
    daemon = false
  }
}
#prometheus-httpserver-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

# Automatically set up the Takipi backend
cinnamon.backends += takipi

cinnamon.takipi {
  backend-class = "cinnamon.takipi.TakipiBackend"
  debug = false
  debug-print-period = 1s

  # The interval at which to update periodic metrics that are polled
  periodic-interval = 10s
}
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

# Automatically add the Jaeger trace reporter
cinnamon.opentracing.tracer.reporters += jaeger

#opentracing-jaeger-reference
cinnamon.opentracing {
  jaeger {
    factory-class = "cinnamon.opentracing.jaeger.JaegerReporterFactory" #exclude-from-docs

    # Host for Jaeger trace span collector
    host = "localhost"

    # UDP port for Jaeger trace span collector
    port = 5775

    # Max size for UDP packets
    max-packet-size = 65000

    # Flush interval for trace span reporter
    flush-interval = 1s

    # Max queue size of trace span reporter
    max-queue-size = 1000

  }
}
#opentracing-jaeger-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#jvm-metrics-reference
cinnamon.chmetrics {
  jvm-metrics {
    registrant-class = "com.lightbend.cinnamon.chmetrics.jvm.JvmMetricsRegistrant" #exclude-from-docs

    memory-usage {
      # Enable memory usage metrics
      metrics = on
      # The category name for all memory usage metrics
      category = "memory-usage"
    }

    garbage-collection {
      # Enable garbage collection metrics
      metrics = on
      # The category name for all garbage collection metrics
      category = "garbage-collection"
    }

    class-loading {
      # Enable class loading metrics
      metrics = on
      # The category name for all class loading metrics
      category = "class-loading"
    }
  }
}
#jvm-metrics-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

cinnamon {
  # Enable cinnamon instrumentation
  instrumentation = on

  # Cinnamon backends
  backends = ${?cinnamon.backends} []

  # Identifier for the host.
  # Defaults to the IP address of the host.
  # Can be set via config, system property, or environment variable.
  host = ${?CINNAMON_HOST}

  # Identifier for the application.
  # Defaults to the main class of the running JVM.
  # Can be set via config, system property, or environment variable.
  application = ${?CINNAMON_APPLICATION}

  meta.identity {
    host {
      # category = "hosts"
      # Use "servers" by default to stay compatible with previous StatsD reporting
      category = "servers"
      key = "host"
    }

    application {
      # category = "applications"
      # Use "apps" by default to stay compatible with previous StatsD reporting
      category = "apps"
      key = "application"
    }
  }
}
#cinnamon-descriptors-executor
cinnamon.core.meta {
  descriptor {
    executor {
      parallelism {
        key = "parallelism"
        name = "Parallelism" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "none"
        unit-suffix = "" #exclude-from-docs
        unit-plural-suffix = "" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      pool-size {
        key = "pool-size"
        name = "Pool size" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "thread"
        unit-plural-suffix = "threads" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      core-pool-size {
        key = "core-pool-size"
        name = "Core pool size" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "thread"
        unit-plural-suffix = "threads" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      max-pool-size {
        key = "max-pool-size"
        name = "Max pool size" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "thread"
        unit-plural-suffix = "threads" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      active-thread-count {
        key = "active-threads"
        name = "Active thread count" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "thread"
        unit-plural-suffix = "threads" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      running-thread-count {
        key = "running-threads"
        name = "Runnning thread count" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "thread"
        unit-plural-suffix = "threads" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      queued-task-count {
        key = "queued-tasks"
        name = "Queued task count" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "task"
        unit-plural-suffix = "tasks" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }

      processed-task-count {
        key = "processed-tasks"
        name = "Processed task count" #exclude-from-docs
        group-name = "metrics" #exclude-from-docs
        categories = ["ExecutorService metrics"] #exclude-from-docs
        unit-type = "custom"
        unit-suffix = "task"
        unit-plural-suffix = "tasks" #exclude-from-docs
        tags = {} #exclude-from-docs
        hints = [] #exclude-from-docs
        enabled = true #exclude-from-docs
      }
    }
  }
}
#cinnamon-descriptors-executor
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#statsd-reporter-reference
cinnamon.chmetrics {
  statsd-reporter {
    reporter-class = "com.lightbend.cinnamon.chmetrics.statsd.StatsDReporter" #exclude-from-docs

    # StatsD host.
    host = "127.0.0.1"

    # StatsD port.
    port = 8125

    # Frequency of metric reporting to StatsD.
    frequency = 10s

    # Prefix for all metric keys.
    prefix = ""

    # Suffix for all metric keys.
    suffix = ""

    report {
      # Histogram fields to report for metrics
      histogram = ["max", "min", "mean", "median", "stddev", "p75", "p95", "p98", "p99", "p999"]

      # Meter fields to report for metrics
      meter = ["samples", "min1_rate", "min5_rate", "min15_rate", "mean_rate"]
    }

    dogstatsd {
      # Whether DogStatsD format should be used
      enabled = off

      # Prefix for all metric keys, when DogStatsD is enabled
      prefix = ${cinnamon.chmetrics.statsd-reporter.prefix}

      # Suffix for all metric keys, when DogStatsD is enabled
      suffix = ${cinnamon.chmetrics.statsd-reporter.suffix}

      # Tags for all metrics, when DogStatsD is enabled.
      # Uses a "key-value" approach to generate the tags.
      # E.g. the following configuration:
      # tags {
      #   country = "UK"
      # }
      # will generate this Datadog tag: "country:UK"
      tags {}

      # Whether to include "unique dimensions" as tags.
      # These are tags that are unique to this reporter,
      # such as host name and application identifier.
      # Off by default for compatibility with earlier versions.
      # Note: host tag is also already provided by DogStatsD
      unique-dimensions = off
    }

    telegraf {
      # Whether Telegraf format should be used or not
      enabled = off

      # Prefix for all metric keys, when Telegraf is enabled
      prefix = ${cinnamon.chmetrics.statsd-reporter.prefix}

      # Suffix for all metric keys, when Telegraf is enabled
      suffix = ${cinnamon.chmetrics.statsd-reporter.suffix}

      # Tags for all metrics, when Telegraf is enabled.
      # Uses a "key-value" approach to generate the tags.
      # E.g. the following configuration:
      # tags {
      #   country = "UK"
      # }
      # will generate this Telegraf tag: "country=UK"
      tags {}

      # Whether to include "unique dimensions" as tags.
      # These are tags that are unique to this reporter,
      # such as host name and application identifier.
      # Off by default for compatibility with earlier versions.
      unique-dimensions = off
    }
  }
}
#statsd-reporter-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

#hdrhistogram-reference
cinnamon.chmetrics {
  histogram {
    hdr {
      factory-class = "com.lightbend.cinnamon.chmetrics.hdrhistogram.HdrHistogramReservoirFactory" #exclude-from-docs

      # Whether to reset the histogram each time a snapshot is taken.
      # If enabled, then the histogram represents the snapshot interval,
      # which will be based on the reporting frequency. Note: only a single
      # reporter can be used when reset-on-snapshot is enabled.
      # If disabled, then the histogram represents the entire lifetime.
      reset-on-snapshot = on

      # Specifies the precision to use. This is the number of significant
      # decimal digits to which the histogram will maintain value resolution
      # and separation. Must be a non-negative integer between 0 and 5.
      significant-value-digits = 2

      # The lowest value that can be tracked (distinguished from 0) by the histogram.
      # Must be a positive integer that is >= 1. If set, requires highest-trackable-value.
      # If set to 0, then use the default (of 1).
      lowest-discernible-value = 0

      # The highest value to be tracked by the histogram.
      # Must be a positive integer that is >= (2 * lowest-discernible-value).
      # If set to 0, then an auto-adjusting highest-trackable-value is used,
      # and it can auto-resize to track values up to (Long.MAX_VALUE / 2).
      highest-trackable-value = 0
    }
  }
}
#hdrhistogram-reference
# Copyright © 2015–2017 Lightbend, Inc. All rights reserved.
# No information contained herein may be reproduced or transmitted in any form
# or by any means without the express written permission of Lightbend, Inc.

cinnamon.producers += jmx-importer

#jmx-reference
cinnamon {
  jmx-importer {
    #jmx-reference
    producer-class = "com.lightbend.cinnamon.jmximporter.JmxImporter"
    #jmx-reference
    identity {
      domain {
        category = "domains"
        key = "domain"
      }

      type {
        category = "types"
        key = "type"
      }

      name {
        category = "names"
        key = "name"
      }

      attribute {
        category = "attributes"
        key = "attribute"
      }
    }

    descriptor {
      group-name = "metrics"
    }
  }
}
#jmx-reference


## Lagom reference.conf snapshot from 2018-05-14 below

lagom.cluster {
  # The cluster node will join itself if akka.cluster.seed-nodes is not configured.
  # In dev-mode this setting will be on, otherwise the default is off. It's possible
  # to override that by defining akka.cluster.seed-nodes or set this property to off in
  # the application.conf
  join-self = ${lagom.defaults.cluster.join-self}

  # Exit the JVM forcefully when the ActorSystem has been terminated.
  # This is by default off, but you may want to turn it on in production
  # to restart the process.
  exit-jvm-when-system-terminated = off

}
lagom.defaults.cluster.join-self = off
play.modules.enabled += com.lightbend.lagom.internal.javadsl.cluster.JoinClusterModule
jdbc-defaults.slick.profile = "slick.jdbc.H2Profile$"
//#persistence
lagom.persistence.jpa {
  # This must match the name in persistence.xml
  persistence-unit = "default"

  # Controls retry when initializing the EntityManagerFactory throws an exception
  initialization-retry {
    # The first retry will be delayed by the min interval
    # Each subsequent delay will be multiplied by the factor
    interval {
      min = 5s
      factor = 1.0
    }

    # After retrying this many times, the final exception will be thrown
    max-retries = 10
  }
}
//#persistence

play.modules.enabled += com.lightbend.lagom.javadsl.persistence.jpa.JpaPersistenceModule
db.default.driver=org.h2.Driver
db.default.url="jdbc:h2:mem:service-test"

jdbc-defaults.slick.profile = "slick.jdbc.H2Profile$"

lagom.spi {
  # Fully qualified class name of the implementation of the 
  # CircuitBreakerMetricsProvider interface. It is created with
  # Guice so you can inject dependencies, such asthe ActorSystem.
  # If not defined (or "") a default implementation will be used.
  circuit-breaker-metrics-class = ""
}
#//#persistence
lagom.persistence {

  # As a rule of thumb, the number of shards should be a factor ten greater
  # than the planned maximum number of cluster nodes. Less shards than number
  # of nodes will result in that some nodes will not host any shards. Too many
  # shards will result in less efficient management of the shards, e.g.
  # rebalancing overhead, and increased latency because the coordinator is
  # involved in the routing of the first message for each shard. The value
  # must be the same on all nodes in a running cluster. It can be changed
  # after stopping all nodes in the cluster.
  max-number-of-shards = 100

  # Persistent entities saves snapshots after this number of persistent
  # events. Snapshots are used to reduce recovery times.
  # It may be configured to "off" to disable snapshots.
  snapshot-after = 100

  # A persistent entity is passivated automatically if it does not receive
  # any messages during this timeout. Passivation is performed to reduce
  # memory consumption. Objects referenced by the entity can be garbage
  # collected after passivation. Next message will activate the entity
  # again, which will recover its state from persistent storage. Set to 0
  # to disable passivation - this should only be done when the number of
  # entities is bounded and their state, sharded across the cluster, will
  # fit in memory.
  passivate-after-idle-timeout = 120s

  # Specifies that entities run on cluster nodes with a specific role.
  # If the role is not specified (or empty) all nodes in the cluster are used.
  # The entities can still be accessed from other nodes.
  run-entities-on-role = ""

  # Default timeout for PersistentEntityRef.ask replies.
  ask-timeout = 5s

  dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 16
    }
    throughput = 1
  }
}
#//#persistence

#//#persistence-read-side
lagom.persistence.read-side {

  # how long should we wait when retrieving the last known offset
  offset-timeout = 5s

  # Exponential backoff for failures in ReadSideProcessor
  failure-exponential-backoff {
    # minimum (initial) duration until processor is started again
    # after failure
    min = 3s

    # the exponential back-off is capped to this duration
    max = 30s

    # additional random delay is based on this factor
    random-factor = 0.2
  }

  # The amount of time that a node should wait for the global prepare callback to execute
  global-prepare-timeout = 20s

  # Specifies that the read side processors should run on cluster nodes with a specific role.
  # If the role is not specified (or empty) all nodes in the cluster are used.
  run-on-role = ""

  # The Akka dispatcher to use for read-side actors and tasks.
  use-dispatcher = "lagom.persistence.dispatcher"
}
#//#persistence-read-side

# Cluster distribution settings
lagom.persistence.cluster.distribution {

  # Each entity is pinged at this interval. Each node will ping this often, so this interval can be quite long.
  ensure-active-interval = 30s
}

akka.actor {
  serializers {
    lagom-persistence-core = "com.lightbend.lagom.internal.persistence.cluster.ClusterStartupTaskSerializer"
  }
  serialization-bindings {
    "com.lightbend.lagom.internal.persistence.cluster.ClusterStartupTaskActor$Execute$" = lagom-persistence-core
  }
  serialization-identifiers {
    # "lagom-persistence-core".hashCode
    "com.lightbend.lagom.internal.persistence.cluster.ClusterStartupTaskSerializer" = -1543173302
  }
}

akka.actor {
  serializers {
    lagom-scaladsl-persistence = "com.lightbend.lagom.internal.scaladsl.persistence.protobuf.PersistenceMessageSerializer"
  }
  serialization-bindings {
    "com.lightbend.lagom.scaladsl.persistence.CommandEnvelope" = lagom-scaladsl-persistence
    "com.lightbend.lagom.scaladsl.persistence.PersistentEntity$InvalidCommandException" = lagom-scaladsl-persistence
    "com.lightbend.lagom.scaladsl.persistence.PersistentEntity$UnhandledCommandException" = lagom-scaladsl-persistence
    "com.lightbend.lagom.scaladsl.persistence.PersistentEntity$PersistException" = lagom-scaladsl-persistence
    "com.lightbend.lagom.internal.persistence.cluster.ClusterDistribution$EnsureActive" = lagom-scaladsl-persistence
  }
  serialization-identifiers {
    "com.lightbend.lagom.internal.scaladsl.persistence.protobuf.PersistenceMessageSerializer" = 1000003
  }
}

play.modules.enabled += com.lightbend.lagom.javadsl.persistence.PersistenceModule

akka.actor {
  serializers {
    lagom-javadsl-persistence = "com.lightbend.lagom.internal.javadsl.persistence.protobuf.PersistenceMessageSerializer"
  }
  serialization-bindings {
    "com.lightbend.lagom.javadsl.persistence.CommandEnvelope" = lagom-javadsl-persistence
    "com.lightbend.lagom.javadsl.persistence.PersistentEntity$InvalidCommandException" = lagom-javadsl-persistence
    "com.lightbend.lagom.javadsl.persistence.PersistentEntity$UnhandledCommandException" = lagom-javadsl-persistence
    "com.lightbend.lagom.javadsl.persistence.PersistentEntity$PersistException" = lagom-javadsl-persistence
    "com.lightbend.lagom.internal.persistence.cluster.ClusterDistribution$EnsureActive" = lagom-javadsl-persistence
  }
  serialization-identifiers {
    "com.lightbend.lagom.internal.javadsl.persistence.protobuf.PersistenceMessageSerializer" = 1000001
  }
}

lagom.pubsub {

  # The subscriber Source has a buffer of this size. 
  subscriber-buffer-size = 1000

}
play.modules.enabled += com.lightbend.lagom.javadsl.pubsub.PubSubModule

lagom.pubsub {

  # The subscriber Source has a buffer of this size. 
  subscriber-buffer-size = 1000

}
lagom {
  akka {  	
    dev-mode {
      actor-system {
        name = "lagom-dev-mode"
      }

      # The dev mode actor system. Lagom typically uses the application actor system, however, in dev mode, an actor
      # system is needed that outlives the application actor system, since the HTTP server will need to use this, and it
      # lives through many application (and therefore actor system) restarts.
      config {
        # Turn off dead letters until Akka HTTP server is stable
        log-dead-letters = off

        # Disable Akka-HTTP's transparent HEAD handling. so that play's HEAD handling can take action
        http.server.transparent-head-requests = false

        akka.actor.provider = akka.actor.LocalActorRefProvider
      }
    }
  }
}
play.modules.enabled += com.lightbend.lagom.internal.javadsl.registry.ServiceRegistryModule
play.modules.enabled += com.lightbend.lagom.play.LagomPlayModule

play.modules.enabled += impl.FooModule
lagom.broker.defaults.kafka {
  # See {lagom.broker.kafka.brokers} for documentation about this
  # configuration key.
  brokers = "localhost:9092"
}

#//#kafka-broker
lagom.broker.kafka {
  # The name of the Kafka service to look up out of the service locator.
  # If this is an empty string, then a service locator lookup will not be done,
  # and the brokers configuration will be used instead.
  service-name = "kafka_native"
  service-name = ${?KAFKA_SERVICE_NAME}

  # The URLs of the Kafka brokers. Separate each URL with a comma.
  # This will be ignored if the service-name configuration is non empty.
  brokers = ${lagom.broker.defaults.kafka.brokers}

  client {
    default {
      # Exponential backoff for failures
      failure-exponential-backoff {
        # minimum (initial) duration until processor is started again
        # after failure
        min = 3s

        # the exponential back-off is capped to this duration
        max = 30s

        # additional random delay is based on this factor
        random-factor = 0.2
      }
    }

    # configuration used by the Lagom Kafka producer
    producer = ${lagom.broker.kafka.client.default}
    producer.role = ""

    # configuration used by the Lagom Kafka consumer
    consumer {
      failure-exponential-backoff = ${lagom.broker.kafka.client.default.failure-exponential-backoff}

      # The number of offsets that will be buffered to allow the consumer flow to
      # do its own buffering. This should be set to a number that is at least as
      # large as the maximum amount of buffering that the consumer flow will do,
      # if the consumer buffer buffers more than this, the offset buffer will
      # backpressure and cause the stream to stop.
      offset-buffer = 100

      # Number of messages batched together by the consumer before the related messages'
      # offsets are committed to Kafka.
      # By increasing the batching-size you are trading speed with the risk of having
      # to re-process a larger number of messages if a failure occurs.
      # The value provided must be strictly greater than zero.
      batching-size = 20

      # Interval of time waited by the consumer before the currently batched messages'
      # offsets are committed to Kafka.
      # This parameter is useful to ensure that messages' offsets are always committed
      # within a fixed amount of time.
      # The value provided must be strictly greater than zero.
      batching-interval = 5 seconds
    }
  }
}
#//#kafka-broker#//#circuit-breaker-default
# Circuit breakers for calls to other services are configured
# in this section. A child configuration section with the same
# name as the circuit breaker identifier will be used, with fallback
# to the `lagom.circuit-breaker.default` section.
lagom.circuit-breaker {

  # Default configuration that is used if a configuration section
  # with the circuit breaker identifier is not defined.
  default {
    # Possibility to disable a given circuit breaker.
    enabled = on

    # Number of failures before opening the circuit.
    max-failures = 10

    # Duration of time after which to consider a call a failure.
    call-timeout = 10s

    # Duration of time in open state after which to attempt to close
    # the circuit, by first entering the half-open state.
    reset-timeout = 15s

    # A whitelist of fqcn of Exceptions that the CircuitBreaker
    # should not consider failures. By default all exceptions are
    # considered failures.
    exception-whitelist = []
  }
}
#//#circuit-breaker-default

#//#web-socket-client-default
#This configures the websocket clients used by this service.
#This is a global configuration and it is currently not possible 
#to provide different configurations if multiple websocket services 
#are consumed.
lagom.client.websocket {

  #This parameter limits the allowed maximum size for the messages 
  #flowing through the WebSocket. A similar limit exists on 
  #the server side, see: 
  #https://www.playframework.com/documentation/2.6.x/ScalaWebSockets#Configuring-WebSocket-Frame-Length
  frame.maxLength = 65536
}
#//#web-socket-client-default
# Possibility to disable the built-in status endpoint
lagom.status-endpoint.enabled = on

lagom.tools.service-discovery=com.lightbend.lagom.internal.javadsl.server.JavadslServiceDiscovery
play.modules.enabled += com.lightbend.lagom.internal.javadsl.broker.kafka.KafkaBrokerModule
play.modules.enabled += "com.lightbend.lagom.javadsl.broker.kafka.KafkaClientModule"
play.modules.enabled += com.lightbend.lagom.internal.javadsl.api.JavadslApiModule
play.modules.enabled += com.lightbend.lagom.internal.javadsl.client.CircuitBreakerModule
#//#persistence-read-side
lagom.persistence.read-side {

  cassandra {

    # Comma-separated list of contact points in the Cassandra cluster
    contact-points = ["127.0.0.1"]

    # Port of contact points in the Cassandra cluster
    port = ${lagom.defaults.persistence.read-side.cassandra.port}

    # The implementation of akka.persistence.cassandra.SessionProvider
    # is used for creating the Cassandra Session. By default the
    # the ServiceLocatorSessionProvider is building the Cluster from configuration
    # and contact points are looked up with ServiceLocator using the configured
    # cluster-id as the service name.
    # Use akka.persistence.cassandra.ConfigSessionProvider to read the contact-points
    # from configuration instead of using the ServiceLocator.
    # It is possible to replace the implementation of the SessionProvider
    # to reuse another session or override the Cluster builder with other
    # settings.
    # The implementation class may optionally have a constructor with an ActorSystem
    # and Config parameter. The config parameter is the enclosing config section.
    session-provider = com.lightbend.lagom.internal.persistence.cassandra.ServiceLocatorSessionProvider

    # The identifier that will be passed as parameter to the
    # ServiceLocatorSessionProvider.lookupContactPoints method.
    cluster-id = "cas_native"
    cluster-id = ${?CASSANDRA_SERVICE_NAME}

    # keyspace must be provided by application.conf
    keyspace = null

    # Parameter indicating whether the read-side keyspace should be auto created
    keyspace-autocreate = true

    # Parameter indicating whether the read-side tables should be auto created
    tables-autocreate = true

    # The number of retries when a write request returns a TimeoutException or an UnavailableException.
    write-retries = 3

    # Deletes are achieved using a metadata entry and then the actual messages are deleted asynchronously
    # Number of retries before giving up
    delete-retries = 3

    # The number of retries when a read query fails.
    read-retries = 3

    # Set this to a positive integer to enable speculative executions.
    # The value defines the number of speculative executions that will be
    # performed with the delay defined by 'speculative-executions-delay'.
    # See http://docs.datastax.com/en/developer/java-driver/3.1/manual/speculative_execution/
    speculative-executions = 0

    # See 'speculative-executions'
    speculative-executions-delay = 1s

    # Number of retries before giving up connecting for the initial connection to the Cassandra cluster
    connect-retries = 3

    # Delay between connection retries, for the initial connection to the Cassandra cluster
    connect-retry-delay = 1s

    # Max delay of the ExponentialReconnectionPolicy that is used when reconnecting
    # to the Cassandra cluster
    reconnect-max-delay = 30s

    # Enable debug logging of queries as described in
    # https://docs.datastax.com/en/developer/java-driver/3.1/manual/logging/#logging-query-latencies
    log-queries = off

    # Cassandra driver connection pool settings
    # Documented at http://docs.datastax.com/en/developer/java-driver/latest/manual/pooling/
    connection-pool {

      # Create new connection threshold local
      new-connection-threshold-local = 800

      # Create new connection threshold remote
      new-connection-threshold-remote = 200

      # Connections per host core local
      connections-per-host-core-local = 1

      # Connections per host max local
      connections-per-host-max-local = 4

      # Connections per host core remote
      connections-per-host-core-remote = 1

      # Connections per host max remote
      connections-per-host-max-remote = 4

      # Max requests per connection local
      max-requests-per-connection-local = 32768

      # Max requests per connection remote
      max-requests-per-connection-remote = 2000

      # Sets the timeout when trying to acquire a connection from a host's pool
      pool-timeout-millis = 0
    }

    # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
    replication-strategy = "SimpleStrategy"

    # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
    replication-factor = 1

    # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
    data-center-replication-factors = []

    # To limit the Cassandra hosts this plugin connects with to a specific datacenter.
    # (DCAwareRoundRobinPolicy withLocalDc)
    # The id for the local datacenter of the Cassandra hosts it should connect to.
    # By default, this property is not set resulting in Datastax's standard round robin policy being used.
    local-datacenter = ""

    # Number of hosts from non-local datacenter to use as a fall-back policy.
    # Works only when local-datacenter is set
    used-hosts-per-remote-dc = 0

    # To connect to the Cassandra hosts with credentials.
    # Authentication is disabled if username is not configured.
    authentication.username = ""
    authentication.password = ""

    # SSL can be configured with the following properties.
    # SSL is disabled if the truststore is not configured.
    # For detailed instructions, please refer to the DataStax Cassandra chapter about
    # SSL Encryption: http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSslEncryptionTOC.html
    # Path to the JKS Truststore file
    ssl.truststore.path = ""
    # Password to unlock the JKS Truststore
    ssl.truststore.password = ""
    # Path to the JKS Keystore file (optional config, only needed for client authentication)
    ssl.keystore.path = ""
    # Password to unlock JKS Truststore and access the private key (both must use the same password)
    ssl.keystore.password = ""

    # Write consistency level
    write-consistency = "QUORUM"

    # Read consistency level
    read-consistency = "QUORUM"

    # Maximum size of result set
    max-result-size = 50001

    # Set the protocol version explicitly, should only be used for compatibility testing.
    # Supported values: 3, 4
    protocol-version = ""

    # Options to configure low-level socket options for the connections to Cassandra hosts
    # See: http://docs.datastax.com/en/developer/java-driver/latest/manual/socket_options
    socket {

      # how long the driver waits to establish a new connection to a Cassandra node before giving up
      connection-timeout-millis = 5000

      # the per-host read timeout in milliseconds. Should be higher than the timeout settings used on the Cassandra side
      read-timeout-millis = 12000

      # a hint to the size of the underlying buffers for outgoing network I/O. Set to zero to
      # use the default from the underlying Netty transport (Java NIO or native epoll)
      send-buffer-size = 0

      # a hint to the size of the underlying buffers for incoming network I/O. Set to zero to
      # use the default from the underlying Netty transport (Java NIO or native epoll)
      receive-buffer-size = 0
    }

  }

}

lagom.defaults.persistence.read-side.cassandra {
  # Port of contact points in the Cassandra cluster
  port = 9042
}
#//#persistence-read-side

cassandra-journal.circuit-breaker.call-timeout = 20s

cassandra-journal.circuit-breaker.call-timeout = 20s
play.modules.enabled += com.lightbend.lagom.javadsl.persistence.cassandra.CassandraPersistenceModule
akka.actor {
  serialization-identifiers {
    "com.lightbend.lagom.scaladsl.playjson.PlayJsonSerializer" = 1000004
  }
}

#//#compress-larger-than
lagom.serialization.json {

  # The serializer will compress the payload if the message class
  # was registered using JsonSerializer.compressed and the payload
  # is larger than this value. Only used for remote messages within
  # the cluster of the service.
  compress-larger-than = 1024b

}
#//#compress-larger-than
//#persistence
# Defaults to use for each Akka persistence plugin
jdbc-defaults.slick {

  # The Slick profile to use
  # set to one of: slick.jdbc.PostgresProfile$, slick.jdbc.MySQLProfile$, slick.jdbc.OracleProfile$ or slick.jdbc.H2Profile$
  # profile = "slick.jdbc.PostgresProfile$"

  # The JNDI name for the Slick pre-configured DB
  # By default, this value will be used by all akka-persistence-jdbc plugin components (journal, read-journal and snapshot).
  # you may configure each plugin component to use different DB settings
  jndiDbName=DefaultDB
}


db.default {

  # The JNDI name for this DataSource
  # Play, and therefore Lagom, will automatically register this DataSource as a JNDI resource using this name.
  # This DataSource will be used to build a pre-configured Slick DB
  jndiName=DefaultDS

  # Lagom will configure a Slick Database, using the async-executor settings below
  # and register it as a JNDI resource using this name.
  # By default, all akka-persistence-jdbc plugin components will use this JDNI name
  # to lookup for this pre-configured Slick DB
  jndiDbName=DefaultDB

  async-executor {
    # number of objects that can be queued by the async executor
    queueSize = 10000

    # 5 * number of cores
    numThreads = 20

    # same as number of threads
    minConnections = 20

    # same as number of threads
    maxConnections = 20

    # if true, a Mbean for AsyncExecutor will be registered
    registerMbeans = false
  }

  # Hikari is the default connection pool and it's fine-tuned to use the same
  # values for minimum and maximum connections as defined for the async-executor above
  hikaricp {
    minimumIdle = ${db.default.async-executor.minConnections}
    maximumPoolSize = ${db.default.async-executor.maxConnections}
  }

  # Alternatively, BoneCP can be used instead of Hikari.
  # More information on how to switch to BoneCP can be found here:
  # https://www.playframework.com/documentation/2.6.x/ScalaDatabase#Selecting-and-configuring-the-connection-pool
  #
  # The settings below configured it to use the same
  # values for minimum and maximum connections as defined for the async-executor above
  bonecp {
    # the pool partition count
    partitionCount = 1

    # the value below is dependent on the partitionCount
    # it must be equal or less than async-executor.minConnections / partitionCount
    minConnectionsPerPartition = ${db.default.async-executor.minConnections}

    # the value below is dependent on the partitionCount
    # it must be equal or less than async-executor.maxConnections / partitionCount
    maxConnectionsPerPartition = ${db.default.async-executor.maxConnections}
  }
}


lagom.persistence.jdbc {

  # Configuration for creating tables
  create-tables {

    # Whether tables should be created automatically as needed
    auto = true

    # How long to wait for tables to be created, before failing
    timeout = 20s

    # The cluster role to create tables from
    run-on-role = ""

    # Exponential backoff for failures configuration for creating tables
    failure-exponential-backoff {

      # minimum (initial) duration until processor is started again
      # after failure
      min = 3s

      # the exponential back-off is capped to this duration
      max = 30s

      # additional random delay is based on this factor
      random-factor = 0.2
    }
  }
}
//#persistence


# configuration settings for Lagom's read-side
# this is NOT the configuration of akka-persistence-jdbc read-side component
lagom.persistence.read-side.jdbc {

  tables {
    # Configuration for the offset table
    offset {
      # The name of the offset table
      tableName = "read_side_offsets"
      # The schema for the offset table
      schemaName = ""
      # The column names
      columnNames {
        # The name of the read side ID column
        readSideId = "read_side_id"
        # The name of the tag column
        tag = "tag"
        # The name of the sequence offset column
        sequenceOffset = "sequence_offset"
        # The name of the time based UUId offset column
        timeUuidOffset = "time_uuid_offset"
      }
    }
  }

  # Slick configuration
  slick {

    # The Slick profile
    profile = ${?jdbc-defaults.slick.profile}

    # The Slick driver - for backward compatibility only, will be removed in 1.5.0 (@deprecated)
    driver = ${?jdbc-defaults.slick.driver}

    jndiDbName = ${jdbc-defaults.slick.jndiDbName}

  }

}
jdbc-defaults.slick.profile = "slick.jdbc.H2Profile$"

jdbc-defaults.slick.profile = "slick.jdbc.H2Profile$"

# Aggressively restart and ensure the cluster-distributed, readside actors so tests don't take that long.
lagom.persistence {
  read-side.failure-exponential-backoff {
    min = 1 s
    max = 2 s
    random-factor = 0.2
  }
}
jdbc-defaults.slick.profile = "slick.jdbc.H2Profile$"

jdbc-defaults.slick.profile = "slick.jdbc.H2Profile$"



# Aggressively restart and ensure the cluster-distributed, readside actors so tests don't take that long.
lagom.persistence {
  read-side.failure-exponential-backoff {
    min = 1 s
    max = 2 s
    random-factor = 0.2
  }
}
play.modules.enabled += com.lightbend.lagom.javadsl.persistence.jdbc.JdbcPersistenceModule
play.modules.enabled += com.lightbend.lagom.javadsl.jackson.JacksonModule

lagom.serialization.json {
  
  #//#jackson-modules
  # The Jackson JSON serializer will register these modules.
  # It is also possible to use jackson-modules = ["*"] to dynamically
  # find and register all modules in the classpath.  
  jackson-modules += "com.fasterxml.jackson.module.paramnames.ParameterNamesModule"
  jackson-modules += "com.fasterxml.jackson.datatype.jdk8.Jdk8Module"
  jackson-modules += "com.fasterxml.jackson.datatype.jsr310.JavaTimeModule"
  jackson-modules += "com.fasterxml.jackson.datatype.pcollections.PCollectionsModule"
  jackson-modules += "com.fasterxml.jackson.datatype.guava.GuavaModule"
  #//#jackson-modules  
  
  # The serializer will compress the payload if the message class
  # implements the CompressedJsonable marker interface and the payload 
  # is larger than this value. Only used for remote messages within 
  # the cluster of the service.
  compress-larger-than = 1024b
  
  # Define data migration transformations of old formats to current 
  # format here as a mapping between the (old) class name to be
  # transformed to the JacksonJsonMigration class that implements
  # the transformation.  
  migrations {
  }
}

akka.actor {
  serializers {
    lagom-json = "com.lightbend.lagom.internal.jackson.JacksonJsonSerializer"
  }
  serialization-bindings {
    "com.lightbend.lagom.serialization.Jsonable" = lagom-json
  }
  serialization-identifiers {
    "com.lightbend.lagom.internal.jackson.JacksonJsonSerializer" = 1000002
  }
}

# Snapshot of all Playframework reference.conf files at 2018-05-14

play {

  modules {
    enabled += "play.api.cache.ehcache.EhCacheModule"
  }

  cache {
    # The name of the xml resource that should be used to configure the cache
    configResource = "ehcache.xml"
    # The caches to bind
    bindCaches = []
    # Whether play should try to create the caches listed in bindCaches
    # If false, the caches should be specified in the ehcache.xml configuration.
    createBoundCaches = true
    # The name of the default cache to use in ehcache
    defaultCache = "play"
    # The dispatcher used for get, set, remove,...  operations on the cache. By default Play's default dispatcher is used.
    dispatcher = null
  }

}
play {
  modules {
    enabled += "play.inject.BuiltInModule"
    enabled += "play.core.ObjectMapperModule"
    enabled += "play.routing.RoutingDslModule"
  }
}

play.application.loader = "play.api.inject.guice.GuiceApplicationLoader"
play.modules.enabled+=play.api.libs.jcache.JCacheModule

play {

  modules {
    enabled += "play.api.db.evolutions.EvolutionsModule"
  }

  # Evolutions configuration
  evolutions {

    # Whether evolutions are enabled
    enabled = true

    # Database schema in which the generated evolution and lock tables will be saved to
    schema = ""

    # Whether evolution updates should be performed with autocommit or in a manually managed transaction
    autocommit = true

    # Whether locks should be used when apply evolutions.  If this is true, a locks table will be created, and will
    # be used to synchronise between multiple Play instances trying to apply evolutions.  Set this to true in a multi
    # node environment.
    useLocks = false

    # Whether evolutions should be automatically applied.  In prod mode, this will only apply ups, in dev mode, it will
    # cause both ups and downs to be automatically applied.
    autoApply = false

    # Whether downs should be automatically applied.  This must be used in combination with autoApply, and only applies
    # to prod mode.
    autoApplyDowns = false

    # Whether evolutions should be skipped, if the scripts are all down.
    skipApplyDownsOnly = false

    # Db specific configuration. Should be a map of db names to configuration in the same format as this.
    db {

    }
  }
}
play {
  modules {
    enabled += "play.libs.ws.ahc.AhcWSModule"
    enabled += "play.libs.openid.OpenIdModule"
    enabled += "play.api.libs.openid.OpenIDModule"
  }
}
play.server {

  # The server provider class name
  provider = "play.core.server.NettyServerProvider"

  netty {

    # The default value of the `Server` header to produce if no explicit `Server`-header was included in a response.
    # If this value is the null and no header was included in the request, no `Server` header will be rendered at all.
    server-header = null
    server-header = ${?play.server.server-header}

    # The number of event loop threads. 0 means let Netty decide, which by default will select 2 times the number of
    # available processors.
    eventLoopThreads = 0

    # The maximum length of the initial line. This effectively restricts the maximum length of a URL that the server will
    # accept, the initial line consists of the method (3-7 characters), the URL, and the HTTP version (8 characters),
    # including typical whitespace, the maximum URL length will be this number - 18.
    maxInitialLineLength = 4096

    # The maximum length of the HTTP headers. The most common effect of this is a restriction in cookie length, including
    # number of cookies and size of cookie values.
    maxHeaderSize = 8192

    # The maximum length of body bytes that Netty will read into memory at a time.
    # This is used in many ways.  Note that this setting has no relation to HTTP chunked transfer encoding - Netty will
    # read "chunks", that is, byte buffers worth of content at a time and pass it to Play, regardless of whether the body
    # is using HTTP chunked transfer encoding.  A single HTTP chunk could span multiple Netty chunks if it exceeds this.
    # A body that is not HTTP chunked will span multiple Netty chunks if it exceeds this or if no content length is
    # specified. This only controls the maximum length of the Netty chunk byte buffers.
    maxChunkSize = 8192

    # Whether the Netty wire should be logged
    log.wire = false

    # The transport to use, either jdk or native.
    # Native socket transport has higher performance and produces less garbage but are only available on linux 
    transport = "jdk"

    # Netty options. Possible keys here are defined by:
    #
    # http://netty.io/4.0/api/io/netty/channel/ChannelOption.html
    #
    # Options that pertain to the listening server socket are defined at the top level, options for the sockets associated
    # with received client connections are prefixed with child.*
    option {

      # Set the size of the backlog of TCP connections.  The default and exact meaning of this parameter is JDK specific.
      # SO_BACKLOG = 100

      child {
        # Set whether connections should use TCP keep alive
        # SO_KEEPALIVE = false

        # Set whether the TCP no delay flag is set
        # TCP_NODELAY = false
      }

    }

  }
}
play {
  modules {
    enabled += "play.api.libs.ws.ahc.AhcWSModule"
    enabled += "play.libs.ws.ahc.AhcWSModule"
  }
}

# Configuration settings for JSR 107 Cache for Play WS.
play.ws.cache {

  # True if caching is enabled for the default WS client, false by default
  enabled = false

  # Calculates heuristic freshness if no explicit freshness is enabled
  # according to https://tools.ietf.org/html/rfc7234#section-4.2.2 with LM-Freshness
  heuristics.enabled = false

  # The name of the cache
  name = "play-ws-cache"

  # A specific caching provider name (e.g. if both ehcache and caffeine are set)
  cachingProviderName = ""

  # The CacheManager resource to use. For example:
  #
  # cacheManagerResource = "ehcache-play-ws-cache.xml"
  #
  # If null, will use the ehcache default URI.
  cacheManagerResource = null

  # The CacheManager URI to use. If non-null, this is used instead of cacheManagerResource.
  cacheManagerURI = null
}

play {

  modules {
    enabled += "play.api.cache.caffeine.CaffeineCacheModule"
  }

  cache {
    # Data that should be used to configure the cache
    caffeine {
      defaults {
        initial-capacity = null
        weak-keys = null
        weak-keys = false
        soft-values = false
        record-stats = false
      }
      caches {}
    }
    # The caches to bind
    bindCaches = []
    # The name of the default cache to use in caffeine
    defaultCache = "play"
    # The dispatcher used for get, set, remove,...  operations on the cache. By default Play's default dispatcher is used.
    dispatcher = null
  }
}
play {

  server {

    # The root directory for the Play server instance. This value can
    # be set by providing a path as the first argument to the Play server
    # launcher script. See `ServerConfig.loadConfiguration`.
    dir = ${?user.dir}

    # HTTP configuration
    http {
      # The HTTP port of the server. Use a value of "disabled" if the server
      # shouldn't bind an HTTP port.
      port = 9000
      port = ${?http.port}

      # The interface address to bind to.
      address = "0.0.0.0"
      address = ${?http.address}

      # The idle timeout for an open connection after which it will be closed
      # Set to null or "infinite" to disable the timeout, but notice that this
      # is not encouraged since timeout are important mechanisms to protect your
      # servers from malicious attacks or programming mistakes.
      idleTimeout = 75 seconds
    }

    # HTTPS configuration
    https {

      # The HTTPS port of the server.
      port = ${?https.port}

      # The interface address to bind to
      address = "0.0.0.0"
      address = ${?https.address}

      # The idle timeout for an open connection after which it will be closed
      # Set to null or "infinite" to disable the timeout, but notice that this
      # is not encouraged since timeout are important mechanisms to protect your
      # servers from malicious attacks or programming mistakes.
      idleTimeout = ${play.server.http.idleTimeout}

      # The SSL engine provider
      engineProvider = "play.core.server.ssl.DefaultSSLEngineProvider"
      engineProvider = ${?play.http.sslengineprovider}

      # HTTPS keystore configuration, used by the default SSL engine provider
      keyStore {
        # The path to the keystore
        path = ${?https.keyStore}

        # The type of the keystore
        type = "JKS"
        type = ${?https.keyStoreType}

        # The password for the keystore
        password = ""
        password = ${?https.keyStorePassword}

        # The algorithm to use. If not set, uses the platform default algorithm.
        algorithm = ${?https.keyStoreAlgorithm}
      }

      # HTTPS truststore configuration
      trustStore {

        # If true, does not do CA verification on client side certificates
        noCaVerification = false
      }

      # Whether JSSE want client auth mode should be used. This means, the server
      # will request a client certificate, but won't fail if one isn't provided.
      wantClientAuth = false

      # Whether JSSE need client auth mode should be used. This means, the server
      # will request a client certificate, and will fail and terminate the session
      # if one isn't provided.
      needClientAuth = false
    }

    # The path to the process id file created by the server when it runs.
    # If set to "/dev/null" then no pid file will be created.
    pidfile.path = ${play.server.dir}/RUNNING_PID
    pidfile.path = ${?pidfile.path}

    websocket {
      # Maximum allowable frame payload length. Setting this value to your application's
      # requirement may reduce denial of service attacks using long data frames.
      frame.maxLength = 64k
      frame.maxLength = ${?websocket.frame.maxLength}
    }

    debug {
      # If set to true this will attach an attribute to each request containing debug information. If the application
      # fails to load (e.g. due to a compile issue in dev mode), then this configuration value is ignored and the debug
      # information is always attached.
      #
      # Note: This configuration option is not part of Play's public API and is subject to change without the usual
      # deprecation cycle.
      addDebugInfoToRequests = false
    }
  }

  editor = ${?PLAY_EDITOR}

}
play {
  modules {
    enabled += "play.data.FormFactoryModule"
    enabled += "play.data.format.FormattersModule"
    enabled += "play.data.validation.ValidatorsModule"
  }
}
play {
  modules {
    enabled += "play.db.jpa.JPAModule"
  }

  jpa {
    # The name of the configuration item from which to read JPA config.
    # So, if set to "jpa", means that "jpa.default" is where the configuration
    # for the database named "default" is found.
    config = "jpa"
  }
}

play.modules {
  enabled += "play.filters.csrf.CSRFModule"
  enabled += "play.filters.cors.CORSModule"
  enabled += "play.filters.csp.CSPModule"
  enabled += "play.filters.headers.SecurityHeadersModule"
  enabled += "play.filters.hosts.AllowedHostsModule"
  enabled += "play.filters.gzip.GzipFilterModule"
  enabled += "play.filters.https.RedirectHttpsModule"
}

play.filters {

  # Default list of enabled filters, configured by play.api.http.EnabledFilters
  enabled += play.filters.csrf.CSRFFilter
  enabled += play.filters.headers.SecurityHeadersFilter
  enabled += play.filters.hosts.AllowedHostsFilter

  # CSRF config
  csrf {

    # Token configuration
    token {
      # The token name
      name = "csrfToken"

      # Whether tokens should be signed or not
      sign = true
    }

    # Cookie configuration
    cookie {
      # If non null, the CSRF token will be placed in a cookie with this name
      name = null

      # Whether the cookie should be set to secure
      secure = ${play.http.session.secure}

      # Whether the cookie should have the HTTP only flag set
      httpOnly = false
    }

    # How much of the body should be buffered when looking for the token in the request body
    body.bufferSize = ${play.http.parser.maxMemoryBuffer}

    # Bypass the CSRF check if this origin is trusted by the CORS filter
    bypassCorsTrustedOrigins = true

    # Header configuration
    header {

      # The name of the header to accept CSRF tokens from.
      name = "Csrf-Token"


      # Defines headers that must be present to perform the CSRF check. If any of these headers are present, the CSRF
      # check will be performed.
      #
      # By default, we only perform the CSRF check if there are Cookies or an Authorization header.
      # Generally, CSRF attacks use a user's browser to execute requests on the client's behalf. If the user does not
      # have an active session, there is no danger of this happening.
      #
      # Setting this to null or an empty object will protect all requests.
      protectHeaders {
        Cookie = "*"
        Authorization = "*"
      }

      # Defines headers that can be used to bypass the CSRF check if any are present. A value of "*" simply
      # checks for the presence of the header. A string value checks for a match on that string.
      bypassHeaders {}
    }

    # Method lists
    method {
      # If non empty, then requests will be checked if the method is not in this list.
      whiteList = ["GET", "HEAD", "OPTIONS"]

      # The black list is only used if the white list is empty.
      # Only check methods in this list.
      blackList = []
    }

    # Content type lists
    # If both white lists and black lists are empty, then all content types are checked.
    contentType {
      # If non empty, then requests will be checked if the content type is not in this list.
      whiteList = []

      # The black list is only used if the white list is empty.
      # Only check content types in this list.
      blackList = []
    }

    routeModifiers {
      # If non empty, then requests will be checked if the route does not have this modifier. This is how we enable the
      # nocsrf modifier, but you may choose to use a different modifier (such as "api") if you plan to check the
      # modifier in your code for other purposes.
      whiteList = ["nocsrf"]

      # If non empty, then requests will be checked if the route contains this modifier
      # The black list is used only if the white list is empty
      blackList = []
    }

    # The error handler.
    # Used by Play's built in DI support to locate and bind a request handler.  Must be one of the following:
    # - A FQCN that implements play.filters.csrf.CSRF.ErrorHandler (Scala).
    # - A FQCN that implements play.filters.csrf.CSRFErrorHandler (Java).
    # - provided, indicates that the application has bound an instance of play.filters.csrf.CSRF.ErrorHandler through some
    #   other mechanism.
    # If null, will attempt to load a class called CSRFErrorHandler in the root package, otherwise if that's
    # not found, will default to play.filters.csrf.CSRF.CSRFHttpErrorHandler, which delegates to the configured
    # HttpRequestHandler.
    errorHandler = null
  }

  # Security headers filter configuration
  headers {

    # The X-Frame-Options header. If null, the header is not set.
    frameOptions = "DENY"

    # The X-XSS-Protection header. If null, the header is not set.
    xssProtection = "1; mode=block"

    # The X-Content-Type-Options header. If null, the header is not set.
    contentTypeOptions = "nosniff"

    # The X-Permitted-Cross-Domain-Policies header. If null, the header is not set.
    permittedCrossDomainPolicies = "master-only"

    # DEPRECATED: Content Security Policy.  If null, the header is not set.
    # This config property is set to null deliberately as the CSPFilter replaces it.
    contentSecurityPolicy = null

    # The Referrer-Policy header. If null, the header is not set.
    referrerPolicy = "origin-when-cross-origin, strict-origin-when-cross-origin"

    # If true, allow an action to use .withHeaders to replace one or more of the above headers
    allowActionSpecificHeaders = false
  }

  # Content Security Policy filter configuration
  # Please see https://playframework.com/documentation/latest/CspFilter for more details.
  csp {
    # If true, the CSP output uses Content-Security-Policy-Report-Only header instead.
    reportOnly = false

    routeModifiers {
      # If non empty, then requests will be checked if the route does not have this modifier.
      whiteList = ["nocsp"]

      # If non empty, then requests will be checked if the route contains this modifier
      # The black list is used only if the white list is empty
      blackList = []
    }

    # #csp-nonce
    # Specify a nonce to be used in CSP security header
    # https://www.w3.org/TR/CSP3/#security-nonces
    #
    # Nonces are used in script and style elements to protect against XSS attacks.
    nonce {
      # Use nonce value (generated and passed in through request attribute)
      enabled = true

      # Pattern to use to replace with nonce
      pattern = "%CSP_NONCE_PATTERN%"

      # Add the nonce to "X-Content-Security-Policy-Nonce" header.  This is useful for debugging.
      header = false
    }
    # #csp-nonce

    # Specify hashes that are used internally in the content security policy.
    # The format of these hashes are as follows:
    #
    # {
    #   algorithm = sha256
    #   hash = "RpniQm4B6bHP0cNtv7w1p6pVcgpm5B/eu1DNEYyMFXc="
    #   pattern = "%CSP_MYSCRIPT_HASH%"
    # }
    #
    # and should be used inline the same way as the nonce pattern, i.e.
    #
    # script-src = "%CSP_MYSCRIPT_HASH% 'strict-dynamic' ..."
    hashes = []

    # #csp-directives
    # The directives here are set to the Google Strict CSP policy by default
    # https://csp.withgoogle.com/docs/strict-csp.html
    directives {
      # base-uri defaults to 'none' according to https://csp.withgoogle.com/docs/strict-csp.html
      # https://www.w3.org/TR/CSP3/#directive-base-uri
      base-uri = "'none'"

      # object-src defaults to 'none' according to https://csp.withgoogle.com/docs/strict-csp.html
      # https://www.w3.org/TR/CSP3/#directive-object-src
      object-src = "'none'"

      # script-src defaults according to https://csp.withgoogle.com/docs/strict-csp.html
      # https://www.w3.org/TR/CSP3/#directive-script-src
      script-src = ${play.filters.csp.nonce.pattern} "'unsafe-inline' 'unsafe-eval' 'strict-dynamic' https: http:"
    }
    # #csp-directives
  }

  # Allowed hosts filter configuration
  hosts {

    # A list of valid hosts (e.g. "example.com") or suffixes of valid hosts (e.g. ".example.com")
    # Note that ".example.com" will match example.com and any subdomain of example.com, with or without a trailing dot.
    # "." matches all domains, and "" matches an empty or nonexistent host.
    allowed = ["localhost", ".local"]
  }

  # CORS filter configuration
  cors {

    # The path prefixes to filter.
    pathPrefixes = ["/"]

    # The allowed origins. If null, all origins are allowed.
    allowedOrigins = null

    # The allowed HTTP methods. If null, all methods are allowed
    allowedHttpMethods = null

    # The allowed HTTP headers. If null, all headers are allowed.
    allowedHttpHeaders = null

    # The exposed headers
    exposedHeaders = []

    # Whether to support credentials
    supportsCredentials = true

    # The maximum amount of time the CORS meta data should be cached by the client
    preflightMaxAge = 1 hour

    # Whether to serve forbidden origins as non-CORS requests
    serveForbiddenOrigins = false
  }

  # GZip filter configuration
  gzip {

    # The buffer size to use for gzipped bytes
    bufferSize = 8k

    # The maximum amount of content to buffer for gzipping in order to calculate the content length before falling back
    # to chunked encoding.
    chunkedThreshold = 100k

    contentType {

        # If non empty, then a response will only be compressed if its content type is in this list.
        whiteList = []

        # The black list is only used if the white list is empty.
        # Compress all responses except the ones whose content type is in this list.
        blackList = []
    }

    # The compression level to use, integer, -1 to 9, inclusive. See java.util.zip.Deflater.
    compressionLevel = -1
  }

  # Configuration for redirection to HTTPS and Strict-Transport-Security
  https {

    # A boolean defining whether the redirect to HTTPS is enabled.
    # A value of null means enabled only in Prod mode, but disabled in Dev/Test.
    redirectEnabled = null

    # The Strict-Transport-Security header is used to signal to browsers to always use https.
    # This header is added whenever the filter makes the redirect.
    # Set to null to disable the header.
    strictTransportSecurity = "max-age=31536000; includeSubDomains"

    # Configures the redirect status code used if the request is not secure.
    # By default, uses HTTP status code 308, which is a permanent redirect that does
    # not change the HTTP method according to [RFC 7238](https://tools.ietf.org/html/rfc7538).
    redirectStatusCode = 308

    # A boolean defining wheter to only redirect if a x-forwarded-proto header is set to http.
    # This is a defacto standard that will be used by various proxys or load balancers to determine
    # if a redirect should happen.
    # [X-Forwarded-Proto](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-Proto)
    xForwardedProtoEnabled = false

    # The HTTPS port to use in the Redirect's Location URL.
    # e.g. port = 9443 results in https://playframework.com:9443/some/url
    port = null
    port = ${?play.server.https.port} # default to same HTTPS port as play server
    port = ${?https.port} # read https.port system property if provided explicitly
  }
}
play.modules.enabled += "play.db.DBModule"
#
# Copyright (C) 2009-2018 Lightbend Inc. <https://www.lightbend.com>
#

# Determines whether HTTP2 is enabled.
play.server.akka.http2 {
  enabled = true
  enabled = ${?http2.enabled}
}
play {
  http {
    secret {
      key = "a test secret"
    }
  }
}#
# Copyright (C) 2009-2018 Lightbend Inc. <https://www.lightbend.com>
#

# Reference configuration for Play

#default timeout for promises
# @richdougherty: Is this used any more?
promise.akka.actor.typed.timeout=5s

play {
  # Defines whether the global application is allowed
  allowGlobalApplication = true

  logger {
    # This is a boolean configuration.
    # If true, the configuration properties will be used when configuring the logger.
    includeConfigProperties = false
  }

  http {

    # The application context.
    # Must start with /.
    context = "/"

    # The error handler.
    # Used by Play's built in DI support to locate and bind a request handler.  Must be the FQCN of a Play router.
    # If null, will attempt to load a class called Routes in the root package, otherwise if that's not found, an empty
    # router will be bound.
    router = null

    # The request handler.
    # Used by Play's built in DI support to locate and bind a request handler.  Must be one of the following:
    # - A FQCN that implements play.api.http.HttpRequestHandler (Scala).
    # - A FQCN that implements play.http.HttpRequestHandler (Java).
    # - provided, indicates that the application has bound an instance of play.api.http.HttpRequestHandler through some
    #   other mechanism.
    # If null, will attempt to load a class called RequestHandler in the root package, otherwise if that's
    # not found, will default to play.api.http.JavaCompatibleHttpRequestHandler.
    requestHandler = null

    # The request handler.
    # Used by Play's built in DI support to locate and bind a request handler.  Must be one of the following:
    # - A FQCN that implements play.http.ActionCreator (Java).
    # If null, will attempt to load a class called ActionCreator in the root package, otherwise if that's
    # not found, will default to play.http.DefaultActionCreator.
    actionCreator = null

    # The error handler.
    # Used by Play's built in DI support to locate and bind an error handler.  Must be one of the following:
    # - A FQCN that implements play.api.http.HttpErrorHandler (Scala).
    # - A FQCN that implements play.http.HttpErrorHandler (Java).
    # - provided, indicates that the application has bound an instance of play.api.http.HttpErrorHandler through some
    #   other mechanism.
    # If null, will attempt to load a class called ErrorHandler in the root package, otherwise if that's
    # not found, will default to play.api.http.DefaultHttpErrorHandler.
    errorHandler = null

    # The filters.
    # Used by Play's built in DI support to locate and bind a class to provide filters.  Must be one of the following:
    # - A FQCN that implements play.api.http.HttpFilters (Scala).
    # - A FQCN that implements play.http.HttpFilters (Java).
    # - provided, indicates that the application has bound an instance of play.api.http.HttpFilters through some
    #   other mechanism.
    # If null, will attempt to load a class called Filters in the root package, otherwise if that's not found, will
    # default to play.api.http.EnabledFilters, which provides the default filters.
    # To disable filters completely, set this to "play.api.http.NoHttpFilters"
    filters = null

    # Forwarded header configuration
    # Play supports various forwarded headers used by proxies to indicate the incoming IP address and protocol of
    # requests. Play uses this in the implementation of the RequestHeader.remoteAddress and RequestHeader.secure
    # fields.
    forwarded = {

      # The version of forwarded headers to use.
      # Valid values are x-forwarded and rfc7239.
      # x-forwarded uses the de facto standard X-Forwarded-For and X-Forwarded-Proto headers to determine the correct
      # remote address and protocol for the request. These headers are widely used, however, they have some serious
      # limitations, for example, if you have multiple proxies, and only one of them adds the X-Forwarded-Proto header,
      # it's impossible to reliably determine which proxy added it and therefore whether the request from the client
      # was made using https or http. rfc7239 uses the new Forwarded header standard, and solves many of the
      # limitations of the X-Forwarded-* headers.
      version = "x-forwarded"

      # The trusted proxies.
      # Trusted proxies may either be individual IPv4 or IPv6 addresses, or be IPv4 or IPv6 CIDR address ranges.
      # This is used to prevent IP address spoofing. Multiple proxies can add and append to the forwarded headers,
      # including the client, which could masquerade as a proxy proxying requests on behalf of another client.  Play
      # will validate that the incoming request IP, and all forwarded headers match the addresses in this list, and will
      # present the first untrusted IP address that it finds (or if all addresses are trusted, the last address) to the
      # application.
      # Note that a number of cloud hosting platforms, most notably AWS, make no guarantees as to what IP addresses
      # their proxies will make requests from. If this is the case, in order for Play to respect the forwarded headers,
      # you need to trust all IP addresses, therefore making it possible for clients to spoof the incoming address.
      # To trust all IP addresses, set this to ["0.0.0.0/0", "::/0"].
      trustedProxies = ["127.0.0.1", "::1"]
    }

    # Parsing configuration
    parser = {

      # The maximum amount of a request body that should be buffered into memory
      maxMemoryBuffer = 100k

      # The maximum amount of a request body that should be buffered into disk
      maxDiskBuffer = 10m
    }

    # Action composition configuration
    actionComposition = {

      # If annotations put directly on Controller classes should be executed before the ones put on action methods
      controllerAnnotationsFirst = false

      # If the action returned by the action creator should be executed before the action composition ones
      executeActionCreatorActionFirst = false
    }

    # Cookies configuration
    cookies = {

      # Whether strict cookie parsing should be used. If true, will ignore the entire cookie header if a single invalid
      # cookie is found, otherwise, will just ignore the invalid cookie if an invalid cookie is found. The reason
      # dropping the entire header may be useful is that browsers don't make any attempt to validate cookie values,
      # which may open opportunities for an attacker to trigger some edge case in the parser to steal cookie
      # information. By dropping the entire header, this makes it harder to exploit edge cases.
      strict = true
    }

    # #session-configuration
    # Session configuration
    session = {

      # The cookie name
      cookieName = "PLAY_SESSION"

      # Whether the secure attribute of the cookie should be set to true
      secure = false

      # The max age to set on the cookie.
      # If null, the cookie expires when the user closes their browser.
      # An important thing to note, this only sets when the browser will discard the cookie.
      maxAge = null

      # Whether the HTTP only attribute of the cookie should be set to true
      httpOnly = true

      # The value of the SameSite attribute of the cookie. Set to null for no SameSite attribute.
      sameSite = "lax"

      # The domain to set on the session cookie
      # If null, does not set a domain on the session cookie.
      domain = null

      # The session path
      # Must start with /.
      path = ${play.http.context}

      jwt {
        # The JWT signature algorithm to use on the session cookie
        # uses 'alg' https://tools.ietf.org/html/rfc7515#section-4.1.1
        signatureAlgorithm = "HS256"

        # The time after which the session is automatically invalidated.
        # Use 'exp' https://tools.ietf.org/html/rfc7519#section-4.1.4
        expiresAfter = ${play.http.session.maxAge}

        # The amount of clock skew to accept between servers when performing date checks
        # If you have NTP or roughtime synchronizing between servers, you can enhance
        # security by tightening this value.
        clockSkew = 5 minutes

        # The claim key under which all user data is stored in the JWT.
        dataClaim = "data"
      }
    }
    # #session-configuration

    # Flash configuration
    flash = {
      # The cookie name
      cookieName = "PLAY_FLASH"

      # Whether the flash cookie should be secure or not
      secure = false

      # Whether the HTTP only attribute of the cookie should be set to true
      httpOnly = true

      # The value of the SameSite attribute of the cookie. Set to null for no SameSite attribute.
      sameSite = "lax"

      # The flash path
      # Must start with /.
      path = ${play.http.context}

      # The domain to set on the flash cookie
      # If null, does not set a domain on the flash cookie.
      domain = ${play.http.session.domain}

      jwt {
        # The JWT signature algorithm to use on the session cookie
        # uses 'alg' https://tools.ietf.org/html/rfc7515#section-4.1.1
        signatureAlgorithm = "HS256"

        # The time after which the session is automatically invalidated.
        # Use 'exp' https://tools.ietf.org/html/rfc7519#section-4.1.4
        expiresAfter = null

        # The amount of clock skew to accept between servers when performing date checks
        # If you have NTP or roughtime synchronizing between servers, you can enhance
        # security by tightening this value.
        clockSkew = 5 minutes

        # The claim key under which all user data is stored in the JWT.
        dataClaim = "data"
      }
    }

    # Secret configuration
    secret {
      # The application secret. Must be set. A value of "changeme" will cause the application to fail to start in
      # production.
      key = "changeme"

      # The JCE provider to use. If null, uses the platform default.
      provider = null
    }

    fileMimeTypes = """
        3dm=x-world/x-3dmf
        3dmf=x-world/x-3dmf
        7z=application/x-7z-compressed
        a=application/octet-stream
        aab=application/x-authorware-bin
        aam=application/x-authorware-map
        aas=application/x-authorware-seg
        abc=text/vndabc
        ace=application/x-ace-compressed
        acgi=text/html
        afl=video/animaflex
        ai=application/postscript
        aif=audio/aiff
        aifc=audio/aiff
        aiff=audio/aiff
        aim=application/x-aim
        aip=text/x-audiosoft-intra
        alz=application/x-alz-compressed
        ani=application/x-navi-animation
        aos=application/x-nokia-9000-communicator-add-on-software
        aps=application/mime
        arc=application/x-arc-compressed
        arj=application/arj
        art=image/x-jg
        asf=video/x-ms-asf
        asm=text/x-asm
        asp=text/asp
        asx=application/x-mplayer2
        au=audio/basic
        avi=video/x-msvideo
        avs=video/avs-video
        bcpio=application/x-bcpio
        bin=application/mac-binary
        bmp=image/bmp
        boo=application/book
        book=application/book
        boz=application/x-bzip2
        bsh=application/x-bsh
        bz2=application/x-bzip2
        bz=application/x-bzip
        c++=text/plain
        c=text/x-c
        cab=application/vnd.ms-cab-compressed
        cat=application/vndms-pkiseccat
        cc=text/x-c
        ccad=application/clariscad
        cco=application/x-cocoa
        cdf=application/cdf
        cer=application/pkix-cert
        cha=application/x-chat
        chat=application/x-chat
        chrt=application/vnd.kde.kchart
        class=application/java
        # ? class=application/java-vm
        com=text/plain
        conf=text/plain
        cpio=application/x-cpio
        cpp=text/x-c
        cpt=application/mac-compactpro
        crl=application/pkcs-crl
        crt=application/pkix-cert
        crx=application/x-chrome-extension
        csh=text/x-scriptcsh
        csp=application/csp-report
        css=text/css
        csv=text/csv
        cxx=text/plain
        dar=application/x-dar
        dcr=application/x-director
        deb=application/x-debian-package
        deepv=application/x-deepv
        def=text/plain
        der=application/x-x509-ca-cert
        dfont=application/x-font-ttf
        dif=video/x-dv
        dir=application/x-director
        divx=video/divx
        dl=video/dl
        dmg=application/x-apple-diskimage
        doc=application/msword
        dot=application/msword
        dp=application/commonground
        drw=application/drafting
        dump=application/octet-stream
        dv=video/x-dv
        dvi=application/x-dvi
        dwf=drawing/x-dwf=(old)
        dwg=application/acad
        dxf=application/dxf
        dxr=application/x-director
        el=text/x-scriptelisp
        elc=application/x-bytecodeelisp=(compiled=elisp)
        eml=message/rfc822
        env=application/x-envoy
        eot=application/vnd.ms-fontobject
        eps=application/postscript
        es=application/x-esrehber
        etx=text/x-setext
        evy=application/envoy
        exe=application/octet-stream
        f77=text/x-fortran
        f90=text/x-fortran
        f=text/x-fortran
        fdf=application/vndfdf
        fif=application/fractals
        fli=video/fli
        flo=image/florian
        flv=video/x-flv
        flx=text/vndfmiflexstor
        fmf=video/x-atomic3d-feature
        for=text/x-fortran
        fpx=image/vndfpx
        frl=application/freeloader
        funk=audio/make
        g3=image/g3fax
        g=text/plain
        gif=image/gif
        gl=video/gl
        gsd=audio/x-gsm
        gsm=audio/x-gsm
        gsp=application/x-gsp
        gss=application/x-gss
        gtar=application/x-gtar
        gz=application/x-compressed
        gzip=application/x-gzip
        h=text/x-h
        hdf=application/x-hdf
        help=application/x-helpfile
        hgl=application/vndhp-hpgl
        hh=text/x-h
        hlb=text/x-script
        hlp=application/hlp
        hpg=application/vndhp-hpgl
        hpgl=application/vndhp-hpgl
        hqx=application/binhex
        hta=application/hta
        htc=text/x-component
        htm=text/html
        html=text/html
        htmls=text/html
        htt=text/webviewhtml
        htx=text/html
        ice=x-conference/x-cooltalk
        ico=image/x-icon
        ics=text/calendar
        icz=text/calendar
        idc=text/plain
        ief=image/ief
        iefs=image/ief
        iges=application/iges
        igs=application/iges
        ima=application/x-ima
        imap=application/x-httpd-imap
        inf=application/inf
        ins=application/x-internett-signup
        ip=application/x-ip2
        isu=video/x-isvideo
        it=audio/it
        iv=application/x-inventor
        ivr=i-world/i-vrml
        ivy=application/x-livescreen
        jam=audio/x-jam
        jav=text/x-java-source
        java=text/x-java-source
        jcm=application/x-java-commerce
        jfif-tbnl=image/jpeg
        jfif=image/jpeg
        jnlp=application/x-java-jnlp-file
        jpe=image/jpeg
        jpeg=image/jpeg
        jpg=image/jpeg
        jps=image/x-jps
        js=application/javascript
        json=application/json
        jut=image/jutvision
        kar=audio/midi
        karbon=application/vnd.kde.karbon
        kfo=application/vnd.kde.kformula
        flw=application/vnd.kde.kivio
        kml=application/vnd.google-earth.kml+xml
        kmz=application/vnd.google-earth.kmz
        kon=application/vnd.kde.kontour
        kpr=application/vnd.kde.kpresenter
        kpt=application/vnd.kde.kpresenter
        ksp=application/vnd.kde.kspread
        kwd=application/vnd.kde.kword
        kwt=application/vnd.kde.kword
        ksh=text/x-scriptksh
        la=audio/nspaudio
        lam=audio/x-liveaudio
        latex=application/x-latex
        lha=application/lha
        lhx=application/octet-stream
        list=text/plain
        lma=audio/nspaudio
        log=text/plain
        lsp=text/x-scriptlisp
        lst=text/plain
        lsx=text/x-la-asf
        ltx=application/x-latex
        lzh=application/octet-stream
        lzx=application/lzx
        m1v=video/mpeg
        m2a=audio/mpeg
        m2v=video/mpeg
        m3u=audio/x-mpegurl
        m=text/x-m
        man=application/x-troff-man
        manifest=text/cache-manifest
        map=application/x-navimap
        mar=text/plain
        mbd=application/mbedlet
        mc$=application/x-magic-cap-package-10
        mcd=application/mcad
        mcf=text/mcf
        mcp=application/netmc
        me=application/x-troff-me
        mht=message/rfc822
        mhtml=message/rfc822
        mid=application/x-midi
        midi=application/x-midi
        mif=application/x-frame
        mime=message/rfc822
        mjf=audio/x-vndaudioexplosionmjuicemediafile
        mjpg=video/x-motion-jpeg
        mm=application/base64
        mme=application/base64
        mod=audio/mod
        moov=video/quicktime
        mov=video/quicktime
        movie=video/x-sgi-movie
        mp2=audio/mpeg
        mp3=audio/mpeg
        mp4=video/mp4
        mpa=audio/mpeg
        mpc=application/x-project
        mpe=video/mpeg
        mpeg=video/mpeg
        mpg=video/mpeg
        mpga=audio/mpeg
        mpp=application/vndms-project
        mpt=application/x-project
        mpv=application/x-project
        mpx=application/x-project
        mrc=application/marc
        ms=application/x-troff-ms
        mv=video/x-sgi-movie
        my=audio/make
        mzz=application/x-vndaudioexplosionmzz
        nap=image/naplps
        naplps=image/naplps
        nc=application/x-netcdf
        ncm=application/vndnokiaconfiguration-message
        nif=image/x-niff
        niff=image/x-niff
        nix=application/x-mix-transfer
        nsc=application/x-conference
        nvd=application/x-navidoc
        o=application/octet-stream
        oda=application/oda
        odb=application/vnd.oasis.opendocument.database
        odc=application/vnd.oasis.opendocument.chart
        odf=application/vnd.oasis.opendocument.formula
        odg=application/vnd.oasis.opendocument.graphics
        odi=application/vnd.oasis.opendocument.image
        odm=application/vnd.oasis.opendocument.text-master
        odp=application/vnd.oasis.opendocument.presentation
        ods=application/vnd.oasis.opendocument.spreadsheet
        odt=application/vnd.oasis.opendocument.text
        oga=audio/ogg
        ogg=audio/ogg
        ogv=video/ogg
        omc=application/x-omc
        omcd=application/x-omcdatamaker
        omcr=application/x-omcregerator
        otc=application/vnd.oasis.opendocument.chart-template
        otf=application/vnd.oasis.opendocument.formula-template
        otg=application/vnd.oasis.opendocument.graphics-template
        oth=application/vnd.oasis.opendocument.text-web
        oti=application/vnd.oasis.opendocument.image-template
        otm=application/vnd.oasis.opendocument.text-master
        otp=application/vnd.oasis.opendocument.presentation-template
        ots=application/vnd.oasis.opendocument.spreadsheet-template
        ott=application/vnd.oasis.opendocument.text-template
        p10=application/pkcs10
        p12=application/pkcs-12
        p7a=application/x-pkcs7-signature
        p7c=application/pkcs7-mime
        p7m=application/pkcs7-mime
        p7r=application/x-pkcs7-certreqresp
        p7s=application/pkcs7-signature
        p=text/x-pascal
        part=application/pro_eng
        pas=text/pascal
        pbm=image/x-portable-bitmap
        pcl=application/vndhp-pcl
        pct=image/x-pict
        pcx=image/x-pcx
        pdb=chemical/x-pdb
        pdf=application/pdf
        pfunk=audio/make
        pgm=image/x-portable-graymap
        pic=image/pict
        pict=image/pict
        pkg=application/x-newton-compatible-pkg
        pko=application/vndms-pkipko
        pl=text/x-scriptperl
        plx=application/x-pixclscript
        pm4=application/x-pagemaker
        pm5=application/x-pagemaker
        pm=text/x-scriptperl-module
        png=image/png
        pnm=application/x-portable-anymap
        pot=application/mspowerpoint
        pov=model/x-pov
        ppa=application/vndms-powerpoint
        ppm=image/x-portable-pixmap
        pps=application/mspowerpoint
        ppt=application/mspowerpoint
        ppz=application/mspowerpoint
        pre=application/x-freelance
        prt=application/pro_eng
        ps=application/postscript
        psd=application/octet-stream
        pvu=paleovu/x-pv
        pwz=application/vndms-powerpoint
        py=text/x-scriptphyton
        pyc=application/x-bytecodepython
        qcp=audio/vndqcelp
        qd3=x-world/x-3dmf
        qd3d=x-world/x-3dmf
        qif=image/x-quicktime
        qt=video/quicktime
        qtc=video/x-qtc
        qti=image/x-quicktime
        qtif=image/x-quicktime
        ra=audio/x-pn-realaudio
        ram=audio/x-pn-realaudio
        rar=application/x-rar-compressed
        ras=application/x-cmu-raster
        rast=image/cmu-raster
        rdf=application/rdf+xml
        rexx=text/x-scriptrexx
        rf=image/vndrn-realflash
        rgb=image/x-rgb
        rm=application/vndrn-realmedia
        rmi=audio/mid
        rmm=audio/x-pn-realaudio
        rmp=audio/x-pn-realaudio
        rng=application/ringing-tones
        rnx=application/vndrn-realplayer
        roff=application/x-troff
        rp=image/vndrn-realpix
        rpm=audio/x-pn-realaudio-plugin
        rt=text/vndrn-realtext
        rtf=application/rtf
        rtx=application/rtx
        rv=video/vndrn-realvideo
        s=text/x-asm
        s3m=audio/s3m
        s7z=application/x-7z-compressed
        saveme=application/octet-stream
        sbk=application/x-tbook
        scm=text/x-scriptscheme
        sdml=text/plain
        sdp=application/sdp
        sdr=application/sounder
        sea=application/sea
        set=application/set
        sgm=text/x-sgml
        sgml=text/x-sgml
        sh=text/x-scriptsh
        shar=application/x-bsh
        shtml=text/x-server-parsed-html
        sid=audio/x-psid
        skd=application/x-koan
        skm=application/x-koan
        skp=application/x-koan
        skt=application/x-koan
        sit=application/x-stuffit
        sitx=application/x-stuffitx
        sl=application/x-seelogo
        smi=application/smil
        smil=application/smil
        snd=audio/basic
        sol=application/solids
        spc=text/x-speech
        spl=application/futuresplash
        spr=application/x-sprite
        sprite=application/x-sprite
        spx=audio/ogg
        src=application/x-wais-source
        ssi=text/x-server-parsed-html
        ssm=application/streamingmedia
        sst=application/vndms-pkicertstore
        step=application/step
        stl=application/sla
        stp=application/step
        sv4cpio=application/x-sv4cpio
        sv4crc=application/x-sv4crc
        svf=image/vnddwg
        svg=image/svg+xml
        svr=application/x-world
        swf=application/x-shockwave-flash
        t=application/x-troff
        talk=text/x-speech
        tar=application/x-tar
        tbk=application/toolbook
        tcl=text/x-scripttcl
        tcsh=text/x-scripttcsh
        tex=application/x-tex
        texi=application/x-texinfo
        texinfo=application/x-texinfo
        text=text/plain
        tgz=application/gnutar
        tif=image/tiff
        tiff=image/tiff
        tr=application/x-troff
        tsi=audio/tsp-audio
        tsp=application/dsptype
        tsv=text/tab-separated-values
        turbot=image/florian
        tte=application/x-font-ttf
        ttf=application/x-font-ttf
        ttl=text/turtle
        txt=text/plain
        uil=text/x-uil
        uni=text/uri-list
        unis=text/uri-list
        unv=application/i-deas
        uri=text/uri-list
        uris=text/uri-list
        ustar=application/x-ustar
        uu=text/x-uuencode
        uue=text/x-uuencode
        vcd=application/x-cdlink
        vcf=text/x-vcard
        vcard=text/x-vcard
        vcs=text/x-vcalendar
        vda=application/vda
        vdo=video/vdo
        vew=application/groupwise
        viv=video/vivo
        vivo=video/vivo
        vmd=application/vocaltec-media-desc
        vmf=application/vocaltec-media-file
        voc=audio/voc
        vos=video/vosaic
        vox=audio/voxware
        vqe=audio/x-twinvq-plugin
        vqf=audio/x-twinvq
        vql=audio/x-twinvq-plugin
        vrml=application/x-vrml
        vrt=x-world/x-vrt
        vsd=application/x-visio
        vst=application/x-visio
        vsw=application/x-visio
        w60=application/wordperfect60
        w61=application/wordperfect61
        w6w=application/msword
        wav=audio/wav
        wb1=application/x-qpro
        wbmp=image/vnd.wap.wbmp
        web=application/vndxara
        webm=video/webm
        wiz=application/msword
        wk1=application/x-123
        wmf=windows/metafile
        wml=text/vnd.wap.wml
        wmlc=application/vnd.wap.wmlc
        wmls=text/vnd.wap.wmlscript
        wmlsc=application/vnd.wap.wmlscriptc
        woff=application/font-woff
        woff2=application/font-woff2
        word=application/msword
        wp5=application/wordperfect
        wp6=application/wordperfect
        wp=application/wordperfect
        wpd=application/wordperfect
        wq1=application/x-lotus
        wri=application/mswrite
        wrl=application/x-world
        wrz=model/vrml
        wsc=text/scriplet
        wsrc=application/x-wais-source
        wtk=application/x-wintalk
        x-png=image/png
        xbm=image/x-xbitmap
        xdr=video/x-amt-demorun
        xgz=xgl/drawing
        xif=image/vndxiff
        xl=application/excel
        xla=application/excel
        xlb=application/excel
        xlc=application/excel
        xld=application/excel
        xlk=application/excel
        xll=application/excel
        xlm=application/excel
        xls=application/excel
        xlt=application/excel
        xlv=application/excel
        xlw=application/excel
        xm=audio/xm
        xml=application/xml
        xmz=xgl/movie
        xpi=application/x-xpinstall
        xpix=application/x-vndls-xpix
        xpm=image/x-xpixmap
        xsr=video/x-amt-showrun
        xwd=image/x-xwd
        xyz=chemical/x-pdb
        z=application/x-compress
        zip=application/zip
        zoo=application/octet-stream
        zsh=text/x-scriptzsh

        # Office 2007 mess - http://wdg.uncc.edu/Microsoft_Office_2007_MIME_Types_for_Apache_and_IIS
        docx=application/vnd.openxmlformats-officedocument.wordprocessingml.document
        docm=application/vnd.ms-word.document.macroEnabled.12
        dotx=application/vnd.openxmlformats-officedocument.wordprocessingml.template
        dotm=application/vnd.ms-word.template.macroEnabled.12
        xlsx=application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
        xlsm=application/vnd.ms-excel.sheet.macroEnabled.12
        xltx=application/vnd.openxmlformats-officedocument.spreadsheetml.template
        xltm=application/vnd.ms-excel.template.macroEnabled.12
        xlsb=application/vnd.ms-excel.sheet.binary.macroEnabled.12
        xlam=application/vnd.ms-excel.addin.macroEnabled.12
        pptx=application/vnd.openxmlformats-officedocument.presentationml.presentation
        pptm=application/vnd.ms-powerpoint.presentation.macroEnabled.12
        ppsx=application/vnd.openxmlformats-officedocument.presentationml.slideshow
        ppsm=application/vnd.ms-powerpoint.slideshow.macroEnabled.12
        potx=application/vnd.openxmlformats-officedocument.presentationml.template
        potm=application/vnd.ms-powerpoint.template.macroEnabled.12
        ppam=application/vnd.ms-powerpoint.addin.macroEnabled.12
        sldx=application/vnd.openxmlformats-officedocument.presentationml.slide
        sldm=application/vnd.ms-powerpoint.slide.macroEnabled.12
        thmx=application/vnd.ms-officetheme
        onetoc=application/onenote
        onetoc2=application/onenote
        onetmp=application/onenote
        onepkg=application/onenote
        # koffice

        # iWork
        key=application/x-iwork-keynote-sffkey
        kth=application/x-iwork-keynote-sffkth
        nmbtemplate=application/x-iwork-numbers-sfftemplate
        numbers=application/x-iwork-numbers-sffnumbers
        pages=application/x-iwork-pages-sffpages
        template=application/x-iwork-pages-sfftemplate

        # Extensions for Mozilla apps (Firefox and friends)
        xpi=application/x-xpinstall
      """
  }

  filters {
    # List of enabled filters as fully qualified class names
    # enabled = []

    # List of disabled filters as fully qualified class names
    disabled = []
  }

  temporaryFile {
    # Removes stale temporary files from the filesystem.  This is a backup
    # to the "remove-on-gc" functionality in the default temporary file creator,
    # for when GC is not happening fast enough.  Uses play.http.blockingIoDispatcher.
    reaper {
      enabled = false
      initialDelay = "5 minutes"
      interval = "5 minutes"
      olderThan = "5 minutes"
    }
  }

  # The ApplicationLoader to use for creating the Application.
  # This MUST either be set in application.conf or in some module.
  #application.loader = null

  modules {

    # The enabled modules that should be automatically loaded.
    enabled += "play.api.inject.BuiltinModule"
    enabled += "play.api.i18n.I18nModule"
    enabled += "play.api.mvc.CookiesModule"
    enabled += "controllers.AssetsModule"

    # A way to disable modules that are automatically enabled
    disabled = []

  }

  # Internationalisation configuration
  i18n {

    # The languages supported by this application
    langs = []

    # A path to prefix message file loading with.  Use this if you want to place your messages resources at some path
    # other than the root application path.
    path = null

    # The name of the cookie to store the Play language in.  This cookie is set when Langs.setLang is invoked, and
    # read when the preferred lang is loaded.
    langCookieName = "PLAY_LANG"

    # Whether the language cookie should be secure or not
    langCookieSecure = false

    # Whether the HTTP only attribute of the cookie should be set to true
    langCookieHttpOnly = false

  }

  akka {

    # The name of the actor system that Play creates
    actor-system = "application"

    # How long Play should wait for Akka to shutdown before timing it.  If "infinite" or null, waits indefinitely.
    shutdown-timeout = infinite

    # The location to read Play's Akka configuration from
    config = "akka"

    # The blocking IO dispatcher, used for serving files/resources from the file system or classpath.
    blockingIoDispatcher {
      fork-join-executor {
        parallelism-factor = 3.0
      }

    }

    # The dev mode actor system. Play typically uses the application actor system, however, in dev mode, an actor
    # system is needed that outlives the application actor system, since the HTTP server will need to use this, and it
    # lives through many application (and therefore actor system) restarts.
    dev-mode {
      # Turn off dead letters until Akka HTTP server is stable
      log-dead-letters = off

      # Disable Akka-HTTP's transparent HEAD handling. so that play's HEAD handling can take action
      http.server.transparent-head-requests = false

      # CoordinatedShutdown is an extension introduced in Akka 2.5 that will
      # perform registered tasks in the order that is defined by the phases.
      # This setup extends Akka's default phases with Play-specific ones.
      coordinated-shutdown {

        # Terminate the ActorSystem in the last phase actor-system-terminate.
        terminate-actor-system = on

        # Exit the JVM (System.exit(0)) in the last phase actor-system-terminate
        # if this is set to 'on'. It is done after termination of the
        # ActorSystem if terminate-actor-system=on, otherwise it is done
        # immediately when the last phase is reached.
        # This is disabled by default since it falls on Play's responsibilities
        # to exit the JVM.
        exit-jvm = off

        # Run the coordinated shutdown when the JVM process exits, e.g.
        # via kill SIGTERM signal.
        # Play takes care of registering a shutdownHook already.
        run-by-jvm-shutdown-hook = off

      }
    }

    # When Play is shutting down an ActorSystem it will use Akka's CoordinatedShutdown. Instead of running all
    # phases you can choose what phase to run. The dafault is to only stop the actor system but Akka cluster
    # users may opt in and replace their current code with the cluster shutdown phases provided by Akka CS.
    # See https://doc.akka.io/docs/akka/current/actors.html?language=scala#coordinated-shutdown
    run-cs-from-phase = "actor-system-terminate"
  }

  #Assets configuration
  assets {

    # The path on the classpath where assets are located (should be the same as the path parameter in route)
    path = "/public"
    # The URL prefix before your asset name (excluding the trailing slash)
    urlPrefix = "/assets"

    #Default behaviour for checkForMinified is false for dev and true for non-dev modes
    checkForMinified = null

    defaultCache = "public, max-age=3600"

    aggressiveCache = "public, max-age=31536000, immutable"

    digest.algorithm = "md5"

    default.charset = "utf-8"

    # registrations which have charset="utf-8" appended to the content-type header.
    textContentTypes = [ "application/json", "application/javascript" ]

    # This defines which compressions of assets are served by the Assets controller
    # and which priorities they have. E.g. having "br" as first entry and "gzip" as
    # second one will serve a brotli compressed asset rather than a gzip compressed
    # asset to a client supporting both compressions.
    #
    # It also defines for which kind of compressed assets we're looking for on the classpath.
    # If you know, you only provide certain kinds of compressions, disable the others to get
    # a little bit more performance out of your application.
    encodings = [
      { accept: "br", extension: "br"}
      { accept: "gzip", extension: "gz" }
      { accept: "xz", extension: "xz" }
      { accept: "bz2", extension: "bz2" }
    ]

  }

}
#
# Copyright (C) 2009-2018 Lightbend Inc. <https://www.lightbend.com>
#

# Configuration for Play's AkkaHttpServer
play {

  server {
    # The server provider class name
    provider = "play.core.server.AkkaHttpServerProvider"

    akka {
      # How long to wait when binding to the listening socket
      bindTimeout = 5 seconds

      # How long a request takes until it times out. Set to null or "infinite" to disable the timeout.
      requestTimeout = infinite

      # Enables/disables automatic handling of HEAD requests.
      # If this setting is enabled the server dispatches HEAD requests as GET
      # requests to the application and automatically strips off all message
      # bodies from outgoing responses.
      # Note that, even when this setting is off the server will never send
      # out message bodies on responses to HEAD requests.
      transparent-head-requests = off

      # If this setting is empty the server only accepts requests that carry a
      # non-empty `Host` header. Otherwise it responds with `400 Bad Request`.
      # Set to a non-empty value to be used in lieu of a missing or empty `Host`
      # header to make the server accept such requests.
      # Note that the server will never accept HTTP/1.1 request without a `Host`
      # header, i.e. this setting only affects HTTP/1.1 requests with an empty
      # `Host` header as well as HTTP/1.0 requests.
      # Examples: `www.spray.io` or `example.com:8080`
      default-host-header = ""

      # The default value of the `Server` header to produce if no
      # explicit `Server`-header was included in a response.
      # If this value is null and no header was included in
      # the request, no `Server` header will be rendered at all.
      server-header = null
      server-header = ${?play.server.server-header}

      # Configures the processing mode when encountering illegal characters in
      # header value of response.
      #
      # Supported mode:
      # `error`  : default mode, throw an ParsingException and terminate the processing
      # `warn`   : ignore the illegal characters in response header value and log a warning message
      # `ignore` : just ignore the illegal characters in response header value
      illegal-response-header-value-processing-mode = warn

      # This setting is set in `akka.http.server.parsing.max-content-length`
      # Play uses the concept of a `BodyParser` to enforce this limit, so we override it to infinite.
      max-content-length = infinite

      # Enables/disables inclusion of an Tls-Session-Info header in parsed
      # messages over Tls transports (i.e., HttpRequest on server side and
      # HttpResponse on client side).
      #
      # See Akka HTTP `akka.http.server.parsing.tls-session-info-header` for
      # more information about how this works.
      tls-session-info-header = on

    }
  }

}
play {

  modules {
    enabled += "play.api.db.DBModule"
    enabled += "play.api.db.HikariCPModule"
  }

  # Database configuration
  db {
    # The name of the configuration item from which to read database config.
    # So, if set to db, means that db.default is where the configuration for the
    # database named default is found.
    config = "db"

    # The name of the default database, used when no database name is explicitly
    # specified.
    default = "default"

    # The default connection pool.
    # Valid values are:
    #  - default - Use the default connection pool provided by the platform (HikariCP)
    #  - hikaricp - Use HikariCP
    #  - A FQCN to a class that implements play.api.db.ConnectionPool
    pool = "default"

    # The prototype for database configuration
    prototype = {

      # The connection pool for this database.
      # Valid values are:
      #  - default - Delegate to play.db.pool
      #  - hikaricp - Use HikariCP
      #  - A FQCN to a class that implements play.api.db.ConnectionPool
      pool = "default"

      # The database driver
      driver = null

      # The database url
      url = null

      # The username
      username = null

      # The password
      password = null

      # If non null, binds the JNDI name to this data source to the given JNDI name.
      jndiName = null

      # If it should log sql statements
      logSql = false

      # HikariCP configuration options
      hikaricp {

        # The datasource class name, if not using a URL
        dataSourceClassName = null

        # Data source configuration options
        dataSource {
        }

        # Whether autocommit should be used
        autoCommit = true

        # The connection timeout
        connectionTimeout = 30 seconds

        # The idle timeout
        idleTimeout = 10 minutes

        # The max lifetime of a connection
        maxLifetime = 30 minutes

        # If non null, the query that should be used to test connections
        connectionTestQuery = null

        # If non null, sets the minimum number of idle connections to maintain.
        minimumIdle = null

        # The maximum number of connections to make.
        maximumPoolSize = 10

        # If non null, sets the name of the connection pool. Primarily used for stats reporting.
        poolName = null

        # This property controls whether the pool will "fail fast" if the pool cannot be seeded with
        # an initial connection successfully.
        # 1. Any positive number is taken to be the number of milliseconds to attempt to acquire an initial connection;
        #    the application thread will be blocked during this period. If a connection cannot be acquired before this
        #    timeout occurs, an exception will be thrown. This timeout is applied after the connectionTimeout period.
        # 2. If the value is zero (0), HikariCP will attempt to obtain and validate a connection. If a connection
        #    is obtained, but fails validation, an exception will be thrown and the pool not started. However, if
        #    a connection cannot be obtained, the pool will start, but later efforts to obtain a connection may fail.
        # 3. A value less than zero will bypass any initial connection attempt, and the pool will start immediately
        #    while trying to obtain connections in the background. Consequently, later efforts to obtain a connection
        #    may fail.
        initializationFailTimeout = 1

        # Sets whether internal queries should be isolated
        isolateInternalQueries = false

        # Sets whether pool suspension is allowed.  There is a performance impact to enabling it.
        allowPoolSuspension = false

        # Sets whether connections should be read only
        readOnly = false

        # Sets whether mbeans should be registered
        registerMbeans = false

        # If non null, sets the catalog that should be used on connections
        catalog = null

        # A SQL statement that will be executed after every new connection creation before adding it to the pool
        connectionInitSql = null

        # If non null, sets the transaction isolation level
        transactionIsolation = null

        # The validation timeout to use
        validationTimeout = 5 seconds

        # If non null, sets the threshold for the amount of time that a connection has been out of the pool before it is
        # considered to have leaked
        leakDetectionThreshold = null
      }
    }
  }
}
